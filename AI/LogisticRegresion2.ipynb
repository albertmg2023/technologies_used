{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Año     Periodo  Euribor\n",
      "0    1999       Enero     3.06\n",
      "1    1999     Febrero     3.03\n",
      "2    1999       Marzo     3.05\n",
      "3    1999       Abril     2.76\n",
      "4    1999        Mayo     2.68\n",
      "..    ...         ...      ...\n",
      "305  2024       Junio     3.65\n",
      "306  2024       Julio     3.53\n",
      "307  2024      Agosto     3.17\n",
      "308  2024  Septiembre     2.94\n",
      "309  2024     Octubre     2.69\n",
      "\n",
      "[310 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "ruta=\"https://raw.githubusercontent.com/AprendizajeAutomaticoUJI/DataSets/master/evolucion_del_euribor_mensual.csv\"\n",
    "data = df = pd.read_csv(ruta, decimal=\",\", sep=\";\")\n",
    "\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculamos media deslizante sobre los datos para identificar las tendencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7623d5d4e450>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"Promedio\"] = data[\"Euribor\"].rolling(12, center=True).mean()\n",
    "plt.plot(df[\"Promedio\"], label=\"Euribor_promedio\", color='b', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AÑOS CON PICO DE EURÍBOR\n",
      "2001\n",
      "2008\n",
      "2011\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "mes_pico=[25,110,150,280]\n",
    "print(\"AÑOS CON PICO DE EURÍBOR\")\n",
    "for i in range(len(mes_pico)):\n",
    "    print(1999+(mes_pico[i]//12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(data[\"Euribor\"], title=\"Autocorrelación de Euribor\");\n",
    "#plot_acf(data[\"Año\"], title=\"Autocorrelación de Euribor\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705766299808152"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Euribor\"].autocorr(12) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiene una correlacion de 0.77 con el valor 12 meses antes o después ,por tanto parece tener una relación cíclica anual el Euríbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 12)\n",
      "(297,)\n",
      "[[3.06 3.03 3.05 ... 3.68 3.69 3.83]\n",
      " [3.03 3.05 2.76 ... 3.69 3.83 3.95]\n",
      " [3.05 2.76 2.68 ... 3.83 3.95 4.11]\n",
      " ...\n",
      " [4.15 4.07 4.15 ... 3.7  3.68 3.65]\n",
      " [4.07 4.15 4.16 ... 3.68 3.65 3.53]\n",
      " [4.15 4.16 4.02 ... 3.65 3.53 3.17]]\n"
     ]
    }
   ],
   "source": [
    "#Funcion que coge steps observaciones(guardadas en dataX) para predecir \n",
    "# la siguiente observacion a las anteriores (que se guarda en dataY) \n",
    "\"\"\"def get_data(df, steps):      \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(len(df)-steps-1):\n",
    "        a = df[i:(i+steps), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(df[i+steps, 0])\n",
    "    return np.array(dataX), np.array(dataY)\"\"\"\n",
    "def get_data(df, steps,col):      \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    \n",
    "    # Recorre el DataFrame para crear las secuencias\n",
    "    for i in range(len(df) - steps - 1):\n",
    "        # Usamos iloc para acceder correctamente a las filas y columnas\n",
    "        a = df.iloc[i:(i + steps), col].values  # Selecciona las filas desde i hasta i+steps de la primera columna\n",
    "        dataX.append(a)\n",
    "        dataY.append(df.iloc[i + steps, col])  # El valor Y es el siguiente después de la secuencia\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "#utilizamos 2 porque es la columna de la inflación \n",
    "# y lo que queremos predecir es el siguiente valor \n",
    "# de la inflación a partir de por ejemplo 12 valores de la inlfación(por ejemplo los del año anterior) \n",
    "X, Y = get_data(data, 12,2)\n",
    "# Verifica las dimensiones de X y y\n",
    "print(X.shape)  # Esto debe mostrar (n_samples, steps), donde n_samples es el número de secuencias\n",
    "print(Y.shape)  # Esto debe mostrar (n_samples,)\n",
    "print(X)\n",
    "#print(datosY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO RNN CON UNA CAPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.7441 - val_loss: 3.3668\n",
      "Epoch 2/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2977 - val_loss: 2.8907\n",
      "Epoch 3/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8799 - val_loss: 2.5206\n",
      "Epoch 4/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6566 - val_loss: 2.2143\n",
      "Epoch 5/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3355 - val_loss: 1.9502\n",
      "Epoch 6/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1441 - val_loss: 1.7101\n",
      "Epoch 7/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1649 - val_loss: 1.4997\n",
      "Epoch 8/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9661 - val_loss: 1.3139\n",
      "Epoch 9/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8653 - val_loss: 1.1442\n",
      "Epoch 10/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7781 - val_loss: 1.0027\n",
      "Epoch 11/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6318 - val_loss: 0.8943\n",
      "Epoch 12/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6214 - val_loss: 0.7979\n",
      "Epoch 13/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4921 - val_loss: 0.7363\n",
      "Epoch 14/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4460 - val_loss: 0.6567\n",
      "Epoch 15/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3943 - val_loss: 0.5941\n",
      "Epoch 16/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3953 - val_loss: 0.5483\n",
      "Epoch 17/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3621 - val_loss: 0.4969\n",
      "Epoch 18/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2481 - val_loss: 0.4569\n",
      "Epoch 19/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2979 - val_loss: 0.4214\n",
      "Epoch 20/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2535 - val_loss: 0.3930\n",
      "Epoch 21/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2248 - val_loss: 0.3646\n",
      "Epoch 22/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2181 - val_loss: 0.3424\n",
      "Epoch 23/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2041 - val_loss: 0.3137\n",
      "Epoch 24/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1901 - val_loss: 0.2983\n",
      "Epoch 25/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1706 - val_loss: 0.2800\n",
      "Epoch 26/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1681 - val_loss: 0.2622\n",
      "Epoch 27/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1828 - val_loss: 0.2560\n",
      "Epoch 28/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1560 - val_loss: 0.2394\n",
      "Epoch 29/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1536 - val_loss: 0.2282\n",
      "Epoch 30/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1474 - val_loss: 0.2199\n",
      "Epoch 31/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1291 - val_loss: 0.2184\n",
      "Epoch 32/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1581 - val_loss: 0.2027\n",
      "Epoch 33/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1378 - val_loss: 0.1951\n",
      "Epoch 34/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1145 - val_loss: 0.1917\n",
      "Epoch 35/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1227 - val_loss: 0.1842\n",
      "Epoch 36/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0983 - val_loss: 0.1808\n",
      "Epoch 37/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1046 - val_loss: 0.1751\n",
      "Epoch 38/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1010 - val_loss: 0.1696\n",
      "Epoch 39/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1007 - val_loss: 0.1660\n",
      "Epoch 40/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0986 - val_loss: 0.1620\n",
      "Epoch 41/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1105 - val_loss: 0.1557\n",
      "Epoch 42/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1046 - val_loss: 0.1515\n",
      "Epoch 43/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0883 - val_loss: 0.1472\n",
      "Epoch 44/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1028 - val_loss: 0.1470\n",
      "Epoch 45/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0912 - val_loss: 0.1419\n",
      "Epoch 46/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.1401\n",
      "Epoch 47/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1031 - val_loss: 0.1341\n",
      "Epoch 48/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0914 - val_loss: 0.1316\n",
      "Epoch 49/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0721 - val_loss: 0.1350\n",
      "Epoch 50/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0965 - val_loss: 0.1297\n",
      "Epoch 51/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0838 - val_loss: 0.1245\n",
      "Epoch 52/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0829 - val_loss: 0.1225\n",
      "Epoch 53/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0743 - val_loss: 0.1205\n",
      "Epoch 54/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0789 - val_loss: 0.1193\n",
      "Epoch 55/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0901 - val_loss: 0.1190\n",
      "Epoch 56/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0632 - val_loss: 0.1140\n",
      "Epoch 57/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0633 - val_loss: 0.1183\n",
      "Epoch 58/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0773 - val_loss: 0.1136\n",
      "Epoch 59/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0755 - val_loss: 0.1104\n",
      "Epoch 60/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0707 - val_loss: 0.1070\n",
      "Epoch 61/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0645 - val_loss: 0.1069\n",
      "Epoch 62/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0730 - val_loss: 0.1039\n",
      "Epoch 63/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.1037\n",
      "Epoch 64/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0672 - val_loss: 0.1022\n",
      "Epoch 65/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0652 - val_loss: 0.1007\n",
      "Epoch 66/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0677 - val_loss: 0.0986\n",
      "Epoch 67/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0582 - val_loss: 0.0961\n",
      "Epoch 68/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0561 - val_loss: 0.0940\n",
      "Epoch 69/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0624 - val_loss: 0.0937\n",
      "Epoch 70/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0918\n",
      "Epoch 71/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0614 - val_loss: 0.0902\n",
      "Epoch 72/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0632 - val_loss: 0.0890\n",
      "Epoch 73/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0527 - val_loss: 0.0876\n",
      "Epoch 74/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0535 - val_loss: 0.0853\n",
      "Epoch 75/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0612 - val_loss: 0.0843\n",
      "Epoch 76/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0675 - val_loss: 0.0852\n",
      "Epoch 77/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0522 - val_loss: 0.0823\n",
      "Epoch 78/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0641 - val_loss: 0.0809\n",
      "Epoch 79/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0525 - val_loss: 0.0811\n",
      "Epoch 80/80\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0515 - val_loss: 0.0787\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0724\n",
      "Pérdida en el conjunto de prueba: 0.07874183356761932\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6S0lEQVR4nO3dd3xTVeMG8OcmadM96YTSwSiUPaUoS5ClCKKvCwUc8CLgQgTBAYiIA/khKuBgi+IoIC8iQyhLqAzLEMoeLbSlrO6Z5Pz+uE1o6CBpk6ZNn+/nk8+9ubnj3BTowznnniMJIQSIiIiI7ITC1gUgIiIisiSGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2RWGG6IyLFu2DJIk4eDBg2V+/tBDDyEsLMxoW1hYGEaOHGnWdfbu3Yvp06cjPT29cgW9i549e6Jnz55WOXdJI0eOLPV9mKq6ynin3NxcTJ8+HTt27Kj2a9tKVX5OpkpOTsb06dNx+PBhq16HqCIqWxeAyF6sXbsWHh4eZh2zd+9ezJgxAyNHjoSXl5fFy7RgwQKLn9Ne5ObmYsaMGQBgk3BlC++++y5effVVq14jOTkZM2bMQFhYGNq2bWvVaxGVh+GGyELatWtn6yIY5ObmwsXFBVFRUbYuit3Qf6e1WaNGjWxdBKJqwWYpIgu5s1lKp9Phgw8+QGRkJJydneHl5YXWrVvj888/BwBMnz4db775JgAgPDwckiRBkiRDM4lOp8Mnn3yCZs2aQa1Ww9/fH8OHD8fly5eNrtuzZ0+0bNkSu3btQteuXeHi4oLnn3/e8NmdtRIzZszAPffcAx8fH3h4eKB9+/ZYvHgxTJ1Dd9myZYiMjIRarUbz5s2xYsWKMvcrLCzEBx98YCi/n58fnnvuOVy7ds2k65Tlp59+QnR0NFxdXeHm5oZ+/fohPj7eaJ+RI0fCzc0NZ8+excCBA+Hm5oaQkBC88cYbKCgoAABcvHgRfn5+hu9D/93rf37Tp0+HJEn4559/8Nhjj8Hb29sQDIQQWLBgAdq2bQtnZ2d4e3vjsccew/nz543Kof+5HDhwAN26dYOLiwsiIiLw0UcfQafTGfbLz8/HG2+8gbZt28LT0xM+Pj6Ijo7Gb7/9Vur+JUnC+PHjsXTpUsOfq44dOyIuLg5CCHz66acIDw+Hm5sb7r//fpw9e7bUd3Nns5Ql72fHjh3o1KkTAOC5554zfK/Tp083nGf9+vWIjo6Gi4sL3N3d8cADD2Dfvn3l/syJKkUQUSlLly4VAERcXJwoKioq9Ro4cKAIDQ01OiY0NFSMGDHC8H727NlCqVSKadOmiW3btolNmzaJefPmienTpwshhEhKShIvv/yyACDWrFkj9u3bJ/bt2ycyMjKEEEKMHj1aABDjx48XmzZtEosWLRJ+fn4iJCREXLt2zXCdHj16CB8fHxESEiK++OILERsbK3bu3Gn4rEePHkblHDlypFi8eLHYunWr2Lp1q5g5c6ZwdnYWM2bMMPl7GTx4sPjf//4nvv/+e9G4cWMREhJi9H1otVrRv39/4erqKmbMmCG2bt0qvvvuO1G/fn0RFRUlcnNzjcp/ZxnLMmvWLCFJknj++efFhg0bxJo1a0R0dLRwdXUVx48fN+w3YsQI4ejoKJo3by7mzJkj/vzzT/Hee+8JSZIM95ifny82bdokAIgXXnjB8N2fPXtWCCHEtGnTBAARGhoqJk+eLLZu3SrWrVsnhBBi1KhRwsHBQbzxxhti06ZN4ocffhDNmjUTAQEBIjU11ei+fH19RZMmTcSiRYvE1q1bxdixYwUAsXz5csN+6enpYuTIkWLlypVi+/btYtOmTWLixIlCoVAY7SeEMJSpa9euYs2aNWLt2rWiadOmwsfHR7z++uti8ODBYsOGDWLVqlUiICBAtG7dWuh0OqPv5s4/t5a8n4yMDMOfkXfeecfwvSYlJQkhhFi1apUAIPr27SvWrVsnfvrpJ9GhQwfh6Ogodu/efdc/A0SmYrghKoP+H+iKXncLNw899JBo27Zthdf59NNPBQBx4cIFo+0JCQkCgBg7dqzR9r///lsAEFOnTjVs69GjhwAgtm3bVur8dwsOWq1WFBUViffff1/4+voa/SIsa9/g4GDRvn17o/0uXrwoHBwcjL6PH3/8UQAQMTExRuc4cOCAACAWLFhgchmFECIxMVGoVCrx8ssvG23PysoSgYGB4vHHHzdsGzFihAAgfv75Z6N9Bw4cKCIjIw3vr127JgCIadOmlbqePty89957Rtv37dsnAIjPPvvMaHtSUpJwdnYWkyZNMrovAOLvv/822jcqKkr069ev3HvVaDSiqKhIvPDCC6Jdu3ZGnwEQgYGBIjs727Bt3bp1AoBo27at0c9l3rx5AoA4evSoYdud4cYa96P/GS9dutRoP/2fn1atWgmtVmvYnpWVJfz9/UXXrl3L/U6IzMVmKaIKrFixAgcOHCj1uu++++56bOfOnXHkyBGMHTsWmzdvRmZmpsnXjY2NBYBST1917twZzZs3x7Zt24y2e3t74/777zfp3Nu3b0efPn3g6ekJpVIJBwcHvPfee7hx4wbS0tLKPe7UqVNITk7G008/DUmSDNtDQ0PRtWtXo303bNgALy8vDBo0CBqNxvBq27YtAgMDzX5CafPmzdBoNBg+fLjR+ZycnNCjR49S55MkCYMGDTLa1rp1a1y6dMms6z766KOl7kuSJDzzzDNG5QgMDESbNm1KlSMwMBCdO3e+azl++eUX3HvvvXBzc4NKpYKDgwMWL16MhISEUmXq1asXXF1dDe+bN28OABgwYIDRz0W/vaJ7ttb9lEX/5+fZZ5+FQnH7V4+bmxseffRRxMXFITc3967nITIFOxQTVaB58+bo2LFjqe2enp5ISkqq8NgpU6bA1dUV33//PRYtWgSlUonu3bvj448/LvOcJd24cQMAEBQUVOqz4ODgUr9MytqvLPv370ffvn3Rs2dPfPvtt2jQoAEcHR2xbt06zJo1C3l5eXctU2BgYKnPAgMDcfHiRcP7q1evIj09HY6OjmWe6/r16yaVt+T5ABj6c9yp5C9LAHBxcYGTk5PRNrVajfz8fLOue+f3evXqVQghEBAQUOb+ERERRu99fX1L7aNWq42+5zVr1uDxxx/Hf/7zH7z55psIDAyESqXCwoULsWTJklLH+/j4GL3Xf8flba/onq1xP+W5259pnU6HW7du1fpO21QzMNwQWYlKpcKECRMwYcIEpKen488//8TUqVPRr18/JCUlVfiPuP6XSEpKCho0aGD0WXJyMurVq2e0reT/2CuyevVqODg4YMOGDUa//NetW3fXY/VlSk1NLfXZndvq1asHX19fbNq0qcxzubu7m1TekucDgF9//RWhoaFmHVsVd36v9erVgyRJ2L17N9Rqdan9y9p2N99//z3Cw8Px008/GV1P3/nZmqxxP+Up+Wf6TsnJyVAoFPD29rbY9ahuY7ghqgZeXl547LHHcOXKFbz22mu4ePEioqKiDL887vyfr76J6fvvvzeqrThw4AASEhLw9ttvV6ockiRBpVJBqVQatuXl5WHlypV3PTYyMhJBQUH48ccfMWHCBMMv4kuXLmHv3r0IDg427PvQQw9h9erV0Gq1uOeeeypV1pL69esHlUqFc+fOlWoqqqzyvvuKPPTQQ/joo49w5coVPP744xYphyRJcHR0NAo2qampZT4tZWnWuJ/yvtfIyEjUr18fP/zwAyZOnGi435ycHMTExBieoCKyBIYbIisZNGgQWrZsiY4dO8LPzw+XLl3CvHnzEBoaiiZNmgAAWrVqBQD4/PPPMWLECDg4OCAyMhKRkZEYPXo0vvjiCygUCgwYMAAXL17Eu+++i5CQELz++uuVKtODDz6IuXPn4umnn8bo0aNx48YNzJkzx6T/oSsUCsycORMvvvgiHnnkEYwaNQrp6emYPn16qaaqJ598EqtWrcLAgQPx6quvonPnznBwcMDly5cRGxuLwYMH45FHHjG53GFhYXj//ffx9ttv4/z58+jfvz+8vb1x9epV7N+/H66uroYB+Uzl7u6O0NBQ/Pbbb+jduzd8fHxQr169CkfwvffeezF69Gg899xzOHjwILp37w5XV1ekpKRgz549aNWqFV566SWzyvHQQw9hzZo1GDt2LB577DEkJSVh5syZCAoKwpkzZ8w6l7mscT+NGjWCs7MzVq1ahebNm8PNzQ3BwcEIDg7GJ598gmHDhuGhhx7Cf//7XxQUFODTTz9Feno6PvroIyvdJdVFDDdEVtKrVy/ExMTgu+++Q2ZmJgIDA/HAAw/g3XffhYODAwB57JApU6Zg+fLl+Pbbb6HT6RAbG4uePXti4cKFaNSoERYvXoyvvvoKnp6e6N+/P2bPnl1m3wdT3H///ViyZAk+/vhjDBo0CPXr18eoUaPg7++PF1544a7H6/f5+OOPMXToUISFhWHq1KnYuXOnUedTpVKJ9evX4/PPP8fKlSsxe/ZsqFQqNGjQAD169DCEOnNMmTIFUVFR+Pzzz/Hjjz+ioKAAgYGB6NSpE8aMGWP2+QBg8eLFePPNN/Hwww+joKAAI0aMwLJlyyo85uuvv0aXLl3w9ddfY8GCBdDpdAgODsa9995bqrOtKZ577jmkpaVh0aJFWLJkCSIiIvDWW2/h8uXLZge2yrD0/bi4uGDJkiWYMWMG+vbti6KiIkybNg3Tp0/H008/DVdXV8yePRtPPPEElEolunTpgtjY2FKd0omqQhLCxJG7iIiIiGoBPgpOREREdoXhhoiIiOwKww0RERHZFYYbIiIisisMN0RERGRXGG6IiIjIrth0nJuFCxdi4cKFhjlpWrRogffeew8DBgwoc/8dO3agV69epbYnJCSgWbNmJl1Tp9MhOTkZ7u7uJg9ZT0RERLYlhEBWVhaCg4NLzSd3J5uGmwYNGuCjjz5C48aNAQDLly/H4MGDER8fjxYtWpR73KlTp+Dh4WF47+fnZ/I1k5OTERISUvlCExERkc0kJSWVmnPvTjVuED8fHx98+umnZY6Wqq+5uXXrFry8vCp1/oyMDHh5eSEpKckoIBEREVHNlZmZiZCQEKSnp8PT07PCfWvM9AtarRa//PILcnJyEB0dXeG+7dq1Q35+PqKiovDOO++U2VSlV1BQYDS7blZWFgDAw8OD4YaIiKiWMaVLic07FB87dgxubm5Qq9UYM2YM1q5di6ioqDL3DQoKwjfffIOYmBisWbMGkZGR6N27N3bt2lXu+WfPng1PT0/Di01SRERE9s3mzVKFhYVITExEenq6YZLBnTt3lhtw7jRo0CBIkoT169eX+fmdNTf6aq2MjAzW3BAREdUSmZmZ8PT0NOn3t82bpRwdHQ0dijt27IgDBw7g888/x9dff23S8V26dMH3339f7udqtRpqtdoiZSUiIqKaz+bh5k5CCKOalruJj49HUFCQFUtERPZKCAGNRgOtVmvrohARAAcHByiVyiqfx6bhZurUqRgwYABCQkKQlZWF1atXY8eOHdi0aRMAYMqUKbhy5QpWrFgBAJg3bx7CwsLQokULFBYW4vvvv0dMTAxiYmJseRtEVAsVFhYiJSUFubm5ti4KERWTJAkNGjSAm5tblc5j03Bz9epVPPvss0hJSYGnpydat26NTZs24YEHHgAApKSkIDEx0bB/YWEhJk6ciCtXrsDZ2RktWrTA77//joEDB9rqFoioFtLpdLhw4QKUSiWCg4Ph6OjIQT2JbEwIgWvXruHy5cto0qRJlWpwbN6huLqZ0yGJiOxTfn4+Lly4gNDQULi4uNi6OERULC8vDxcvXkR4eDicnJyMPjPn97fNHwUnIrKVuw3hTkTVy1I1qPybTURERHaF4YaIyI59/vnn2Ldvn62LQVStGG6IiOzU3LlzsWbNGrRv375Sx/fs2ROvvfaa4X1YWBjmzZtX4TGSJGHdunWVuh5VH1N+lrUZww0RUS0ycuRISJIESZLg4OCAiIgITJw4ETk5OUb7xcXFYeXKlfjtt98sNpDpgQMHMHr0aIucqzbasWMHJElCenq6rYtSZdb4Wd4Zhm2pxg3iV2tlXQV2zwEKc4AhC2xdGiKyY/3798fSpUtRVFSE3bt348UXX0ROTg4WLlxo2KdLly6Ij4+/67mEENBqtVCp7v7rwM/Pr0rlrisKCwvh6Oho62JUyN5/lqy5saT93wBHfgS0RbYuCRGZSQiB3EKNTV7mjsihVqsRGBiIkJAQPP300xg2bJihKUgIgU8++QQRERFwdnZGmzZt8OuvvxqO1dc+bN68GR07doRarcbu3buRk5OD4cOHw83NDUFBQfjss89KXffOpowzZ86ge/fucHJyQlRUFLZu3VrqmMmTJ6Np06ZwcXFBREQE3n33XRQVVfxv5JUrV/DEE0/A29sbvr6+GDx4MC5evGj4fOTIkRgyZAjmzJmDoKAg+Pr6Yty4cXc97//+9z906NABTk5OiIiIwIwZM6DRaAyfS5KE7777Do888ghcXFzQpEkTw7yFFy9eRK9evQAA3t7ekCQJI0eOBCDXWIwfPx4TJkxAvXr1DGO1nThxAgMHDoSbmxsCAgLw7LPP4vr164br9ezZE6+88gomTZoEHx8fBAYGYvr06UZlnjt3Llq1agVXV1eEhIRg7NixyM7ONny+bNkyeHl5YcOGDYiMjISLiwsee+wx5OTkYPny5QgLC4O3tzdefvllo5G47/xZZmRkYPTo0fD394eHhwfuv/9+HDlyxPD59OnT0bZtW6xcuRJhYWHw9PTEk08+iaysLMPPZOfOnfj8888NNYv6n9nOnTvRuXNnqNVqBAUF4a233jL63q2BNTeW4uoHKNWAtgDISgG8Gtq6RERkhrwiLaLe22yTa594vx9cHCv/z7Gzs7PhF/s777yDNWvWYOHChWjSpAl27dqFZ555Bn5+fujRo4fhmEmTJmHOnDmIiIiAl5cX3nzzTcTGxmLt2rUIDAzE1KlTcejQIbRt27bMa+p0OgwdOhT16tVDXFwcMjMzy2yScHd3x7JlyxAcHIxjx45h1KhRcHd3x6RJk8o8b25uLnr16oVu3bph165dUKlU+OCDD9C/f38cPXrUUCMSGxuLoKAgxMbG4uzZs3jiiSfQtm1bjBo1qszzbt68Gc888wzmz5+Pbt264dy5c4ZmmWnTphn2mzFjBj755BN8+umn+OKLLzBs2DBcunQJISEhiImJwaOPPopTp07Bw8MDzs7OhuOWL1+Ol156CX/99ReEEEhJSUGPHj0watQozJ07F3l5eZg8eTIef/xxbN++3ei4CRMm4O+//8a+ffswcuRI3HvvvYaApFAoMH/+fISFheHChQsYO3YsJk2ahAULbrcQ5ObmYv78+Vi9ejWysrIwdOhQDB06FF5eXti4cSPOnz+PRx99FPfddx+eeOKJUt+NEAIPPvggfHx8sHHjRnh6euLrr79G7969cfr0afj4+AAAzp07h3Xr1mHDhg24desWHn/8cXz00UeYNWsWPv/8c5w+fRotW7bE+++/D0CuHbpy5QoGDhyIkSNHYsWKFTh58iRGjRoFJyenUkHOkhhuLEWhADzrAzfPA+lJDDdEVC3279+PH374Ab1790ZOTg7mzp2L7du3Izo6GgAQERGBPXv24OuvvzYKN++//77hF2h2djYWL16MFStWGLYtX74cDRo0KPe6f/75JxISEnDx4kXDfh9++CEGDBhgtN8777xjWA8LC8Mbb7yBn376qdxws3r1aigUCnz33XeGMU+WLl0KLy8v7NixA3379gUg1558+eWXUCqVaNasGR588EFs27at3HAza9YsvPXWWxgxYoThe5k5cyYmTZpkFG5GjhyJp556ynA/X3zxBfbv34/+/fsbfsn7+/vDy8vL6PyNGzfGJ598Ynj/3nvvoX379vjwww8N25YsWYKQkBCcPn0aTZs2BQC0bt3acP0mTZrgyy+/xLZt2ww/h5KBMTw8HDNnzsRLL71kFG6KioqwcOFCNGrUCADw2GOPYeXKlbh69Src3NwQFRWFXr16ITY2tsxwExsbi2PHjiEtLc3QP2vOnDlYt24dfv31V0MI1Ol0WLZsGdzd3QEAzz77LLZt24ZZs2bB09MTjo6OcHFxQWBgoOHcCxYsQEhICL788ktIkoRmzZohOTkZkydPxnvvvWe1saYYbizJs4EcbjIu27okRGQmZwclTrzfz2bXNseGDRvg5uYGjUaDoqIiDB48GF988QVOnDiB/Px8wy9GvcLCQrRr185oW8eOHQ3r586dQ2FhoSEQAYCPjw8iIyPLLUNCQgIaNmxoFIBKHq/366+/Yt68eTh79iyys7Oh0WgqHF320KFDOHv2rOEXqF5+fj7OnTtneN+iRQuj4fmDgoJw7NixCs974MABzJo1y7BNq9UiPz8fubm5hpGqW7dubfjc1dUV7u7uSEtLK/e8eiW/T/31YmNjy5wj6dy5c0bhpqSgoCCj68XGxuLDDz/EiRMnkJmZCY1Gg/z8fOTk5MDV1RUA4OLiYgg2ABAQEICwsDCjawcEBJR7H4cOHUJ2djZ8fX2Ntufl5Rl952FhYUY/lzvLWpaEhARER0cbDc537733Ijs7G5cvX0bDhtapCGC4sSTPEHmZkWTbchCR2SRJqlLTUHXq1asXFi5cCAcHBwQHB8PBwQEAcOHCBQDA77//jvr16xsdc+cTU/pfjADM7vNT3jF3ji4bFxeHJ598EjNmzEC/fv3g6emJ1atXl9mfR0+n06FDhw5YtWpVqc9KdoLV33PJa+t0ugrPO2PGDAwdOrTUZyWH+Tf3vHolv0/99QYNGoSPP/641L5BQUEmXe/SpUsYOHAgxowZg5kzZ8LHxwd79uzBCy+8YNS/qKxzmHMfOp0OQUFB2LFjR6nPStZQVea7EUKU+nOh/7Njzfncasff5NrCEG5Yc0NE1uPq6orGjRuX2h4VFQW1Wo3ExESjJqi7ady4MRwcHBAXF2f4n/StW7dw+vTpcs8TFRWFxMREJCcnIzg4GABKDRb4119/ITQ0FG+//bZh26VLlyosS/v27fHTTz8ZOrZaSvv27XHq1KkyvzdT6fv7lOyYW9H1YmJiEBYWZtKTaGU5ePAgNBoNPvvsM0Pzzc8//1ypc1Wkffv2SE1NhUqlQlhYWKXP4+joWOq7iYqKQkxMjFHI2bt3L9zd3UsFcEvi01KW5FlcPcuaGyKyAXd3d0ycOBGvv/46li9fjnPnziE+Ph5fffUVli9fXu5xbm5ueOGFF/Dmm29i27Zt+PfffzFy5MgK+0P06dMHkZGRGD58OI4cOYLdu3cbhRhADk2JiYlYvXo1zp07h/nz52Pt2rUV3sOwYcNQr149DB48GLt378aFCxewc+dOvPrqq7h8ufL/cXzvvfewYsUKTJ8+HcePH0dCQgJ++uknoz5BdxMaGgpJkrBhwwZcu3bN6KmlO40bNw43b97EU089hf379+P8+fPYsmULnn/+eZPCEQA0atQIGo0GX3zxBc6fP4+VK1di0aJFJpfXVH369EF0dDSGDBmCzZs34+LFi9i7dy/eeecdHDx40OTzhIWF4e+//8bFixdx/fp16HQ6jB07FklJSXj55Zdx8uRJ/Pbbb5g2bRomTJhg1bndGG4syRBuWHNDRLYxc+ZMvPfee5g9ezaaN2+Ofv364X//+x/Cw8MrPO7TTz9F9+7d8fDDD6NPnz6477770KFDh3L3VygUWLt2LQoKCtC5c2e8+OKLRv1ZAGDw4MF4/fXXMX78eLRt2xZ79+7Fu+++W2E5XFxcsGvXLjRs2BBDhw5F8+bN8fzzzyMvL69KNTn9+vXDhg0bsHXrVnTq1AldunTB3LlzERoaavI56tevjxkzZuCtt95CQEAAxo8fX+6+wcHB+Ouvv6DVatGvXz+0bNkSr776Kjw9PU3+pd62bVvMnTsXH3/8MVq2bIlVq1Zh9uzZJpfXVJIkYePGjejevTuef/55NG3aFE8++SQuXryIgIAAk88zceJEKJVKREVFwc/PD4mJiahfvz42btyI/fv3o02bNhgzZgxeeOEFs0JlZUiiMo2ttZg5U6ab7fpZ4MsOgKMbMOUyYMX2RCKqvPz8fFy4cAHh4eFG/S2IyLYq+rtpzu9v1txYkmdx+2FhNpCfbtOiEBER1VUMN5bk4CwP5gfIY90QERFRtWO4sTT2uyEiIrIphhtL4+PgRERENsVwY2mGcJNo23IQERHVUQw3lsZmKSIiIptiuLE0hhsiIiKbYrixNC/2uSEiIrIlhhtL0/e5yUoFNIW2LQsR1Xmff/55qTmfyD5dv34dM2bMwPXr121dFJtjuLE0F19A5QRAAJlXbF0aIqrD5s6dizVr1qB9+/aVOr5nz5547bXXDO/DwsIwb968Co+RJAnr1q2r1PVqupEjR2LIkCGG93d+P2Ux5TszR3nXFEJg+PDhAIB69epZ7Hq1FWcFtzRJkvvd3DgrN035VDyfCxGROUaOHGmYBFOlUiEkJARDhw7FjBkz4OrqatgvLi4OK1euRGxsLNRqtUWufeDAAaNr1HVr1qyBg4NDjbjmxx9/jICAAEybNq1ay1NTMdxYg2fI7XBDRGRh/fv3x9KlS1FUVITdu3fjxRdfRE5ODhYuXGjYp0uXLoiPj7/ruYQQ0Gq1UKnu/uvAz8+vSuW2Nz4+PjXmmm+99VY1l6RmY7OUNRiemOIUDES1hhBAYY5tXmbOX6xWqxEYGIiQkBA8/fTTGDZsmKEpSAiBTz75BBEREXB2dkabNm3w66+/Go7dsWMHJEnC5s2b0bFjR6jVauzevRs5OTkYPnw43NzcEBQUhM8++6zUde9sYjlz5gy6d+8OJycnREVFYevWraWOmTx5Mpo2bQoXFxdERETg3XffRVFRUYX3d+XKFTzxxBPw9vaGr68vBg8ejIsXLxo+1zcPzZkzB0FBQfD19cW4cePKPe+pU6cgSRJOnjxptH3u3LkICwszBLwXXngB4eHhcHZ2RmRkJD7//PMKy3lnE1FaWhoGDRoEZ2dnhIeHY9WqVaWOmTt3Llq1agVXV1eEhIRg7NixyM7ONtrnr7/+Qo8ePeDi4gJvb2/069cPt27dKvOat27dwvDhw+Ht7Q0XFxcMGDAAZ86cMXy+bNkyeHl5YfPmzWjevDnc3NzQv39/pKSkVHhvtR1rbqzBMJAfww1RrVGUC3wYbJtrT00GHCvf3OPs7Gz4xf7OO+9gzZo1WLhwIZo0aYJdu3bhmWeegZ+fH3r06GE4ZtKkSZgzZw4iIiLg5eWFN998E7GxsVi7di0CAwMxdepUHDp0CG3bti3zmjqdDkOHDkW9evUQFxeHzMzMMvuCuLu7Y9myZQgODsaxY8cwatQouLu7Y9KkSWWeNzc3F7169UK3bt2wa9cuqFQqfPDBB+jfvz+OHj0KR0dHAEBsbCyCgoIQGxuLs2fP4oknnkDbtm0xatSoUueMjIxEhw4dsGrVKsycOdOw/YcffsDTTz8NSZKg0+nQoEED/Pzzz6hXrx727t2L0aNHIygoCI8//rhJP4eRI0ciKSkJ27dvh6OjI1555RWkpaUZ7aNQKDB//nyEhYXhwoULGDt2LCZNmoQFCxYAAA4fPozevXvj+eefx/z586FSqRAbGwutVlvuNc+cOYP169fDw8MDkydPxsCBA3HixAlD81Vubi7mzJmDlStXQqFQ4JlnnsHEiRPLDF/2guHGGvg4OBFVk/379+OHH35A7969kZOTg7lz52L79u2Ijo4GAERERGDPnj34+uuvjcLN+++/jwceeAAAkJ2djcWLF2PFihWGbcuXL0eDBg3Kve6ff/6JhIQEXLx40bDfhx9+iAEDBhjt98477xjWw8LC8MYbb+Cnn34qN9ysXr0aCoUC3333HSRJAgAsXboUXl5e2LFjB/r27QsA8Pb2xpdffgmlUolmzZrhwQcfxLZt28oMNwAwbNgwfPnll4Zwc/r0aRw6dAgrVqwAADg4OGDGjBmG/cPDw7F37178/PPPJoWb06dP448//kBcXBzuueceAMDixYvRvHlzo/1KBsDw8HDMnDkTL730kiHcfPLJJ+jYsaPhPQC0aNGizGvqQ81ff/2Frl27AgBWrVqFkJAQrFu3Dv/5z38AAEVFRVi0aBEaNWoEABg/fjzef//9u95TbcZwYw0cyI+o9nFwkWtQbHVtM2zYsAFubm7QaDQoKirC4MGD8cUXX+DEiRPIz883BBS9wsJCtGvXzmhbx44dDevnzp1DYWGhIRABct+OyMjIcsuQkJCAhg0bGgWgksfr/frrr5g3bx7Onj2L7OxsaDQaeHh4lHveQ4cO4ezZs3B3dzfanp+fj3Pnzhnet2jRAkql0vA+KCgIx44dK/e8Tz75JN58803ExcWhS5cuWLVqFdq2bYuoqCjDPosWLcJ3332HS5cuIS8vD4WFheXWXN0pISEBKpXK6Htt1qwZvLy8jPaLjY3Fhx9+iBMnTiAzMxMajQb5+fnIycmBq6srDh8+bAglpl5TH6YAwNfXF5GRkUhISDBsc3FxMQQbQP6u7qxRsjcMN9agDzfpSXJbevH/PoioBpOkKjUNVadevXph4cKFcHBwQHBwsKH54cKFCwCA33//HfXr1zc65s4npko+9STM7PNT3jHSHf/WxcXF4cknn8SMGTPQr18/eHp6YvXq1WX259HT6XSGJqQ7lezQfOcTQ/qmpfIEBQWhV69e+OGHH9ClSxf8+OOP+O9//2v4/Oeff8brr7+Ozz77DNHR0XB3d8enn36Kv//+u9xzlqT/Pu78Dkq6dOkSBg4ciDFjxmDmzJnw8fHBnj178MILLxiaFZ2dnU26XslrlrW9ZDnK+q4q8zOvTRhurMGj+B8VTR6QexNw9bVteYjIrri6uqJx48altkdFRUGtViMxMdGoCepuGjduDAcHB8TFxaFhw4YA5I6qp0+fLvc8UVFRSExMRHJyMoKD5b5Kdw4W+NdffyE0NBRvv/22YdulS5cqLEv79u3x008/wd/fv8IansoYNmwYJk+ejKeeegrnzp3Dk08+afhs9+7d6Nq1K8aOHWvYVrKm6G6aN28OjUaDgwcPonPnzgDkjszp6emGfQ4ePAiNRoPPPvsMCoX8PM/PP/9sdJ7WrVtj27ZtRk1k5YmKioJGo8Hff/9taJa6ceMGTp8+Xao5rK7h01LWoFIDboHyOjsVE1E1cXd3x8SJE/H6669j+fLlOHfuHOLj4/HVV18ZxsYpi5ubG1544QW8+eab2LZtG/7991+MHDnS8Au4LH369EFkZCSGDx+OI0eOYPfu3UYhBpBDU2JiIlavXo1z585h/vz5WLt2bYX3MGzYMNSrVw+DBw/G7t27ceHCBezcuROvvvoqLl+uWlP/0KFDkZmZiZdeegm9evUyqt1q3LgxDh48iM2bN+P06dN49913ceDAAZPPHRkZif79+2PUqFH4+++/cejQIbz44otGNTGNGjWCRqPBF198gfPnz2PlypVYtGiR0XmmTJmCAwcOYOzYsTh69ChOnjyJhQsXljnqcJMmTTB48GCMGjUKe/bswZEjR/DMM8+gfv36GDx4cCW+IfvBcGMtfByciGxg5syZeO+99zB79mw0b94c/fr1w//+9z+Eh1c8oOinn36K7t274+GHH0afPn1w3333oUOHDuXur1AosHbtWhQUFKBz58548cUXMWvWLKN9Bg8ejNdffx3jx49H27ZtsXfvXrz77rsVlsPFxQW7du1Cw4YNMXToUDRv3hzPP/888vLyqlyT4+HhgUGDBuHIkSMYNmyY0WdjxozB0KFD8cQTT+Cee+7BjRs3jGpxTLF06VKEhISgR48eGDp0KEaPHg1/f3/D523btsXcuXPx8ccfo2XLlli1ahVmz55tdI6mTZtiy5YtOHLkCDp37ozo6Gj89ttv5Y5DtHTpUnTo0AEPPfQQoqOjIYTAxo0bq31wwZpGEvbe8HaHzMxMeHp6IiMjw+JVnkZ+HgGcWAf0/wjo8pL1rkNEZsvPz8eFCxcQHh4OJycnWxeHiIpV9HfTnN/frLmxFj4xRUREZBMMN9biJXfKY7MUERFR9WK4sZaSj4MTERFRtWG4sRY2SxEREdmETcPNwoUL0bp1a3h4eMDDwwPR0dH4448/Kjxm586d6NChA5ycnBAREVHqMboaQz+/VE4aUJRv27IQUZnq2PMURDWepf5O2jTcNGjQAB999BEOHjyIgwcP4v7778fgwYNx/PjxMve/cOECBg4ciG7duiE+Ph5Tp07FK6+8gpiYmGouuQmcvQGH4hFAM6/YtixEZKTkhIJEVHMUFhYCgNHUGpVh0xGKBw0aZPR+1qxZWLhwIeLi4sqcKGzRokVo2LAh5s2bB0AeEfLgwYOYM2cOHn300eoosukkSW6aun5K7lTs2+juxxBRtVAqlfDy8jLMr+Pi4lLhsPlEZH06nQ7Xrl2Di4tLueP6mKrGTL+g1Wrxyy+/ICcnp8zJ1wB5aG/9jLB6/fr1w+LFi1FUVFTmoEUFBQUoKCgwvM/MzLRswStiCDfsd0NU0wQGyqOI2/sEgkS1iUKhQMOGDav8nw2bh5tjx44hOjoa+fn5cHNzw9q1a41maS0pNTUVAQEBRtsCAgKg0Whw/fp1BAUFlTpm9uzZJs3RYRVexf1uGG6IahxJkhAUFAR/f3/DpIVEZFuOjo4VTvthKpuHm8jISBw+fBjp6emIiYnBiBEjsHPnznIDzp1p7m4zsU6ZMgUTJkwwvM/MzERISIiFSn8XfBycqMZTKpVVbt8noprF5uHG0dHRMLttx44dceDAAXz++ef4+uuvS+0bGBiI1NRUo21paWlQqVTw9S175m21Wg21Wm35gptC/8QUB/IjIiKqNjVunBshhFEfmZKio6OxdetWo21btmxBx44da+YkYRzrhoiIqNrZNNxMnToVu3fvxsWLF3Hs2DG8/fbb2LFjh2G21ilTpmD48OGG/ceMGYNLly5hwoQJSEhIwJIlS7B48WJMnDjRVrdQMc8SfW44ngYREVG1sGmz1NWrV/Hss88iJSUFnp6eaN26NTZt2oQHHngAAJCSkoLExETD/uHh4di4cSNef/11fPXVVwgODsb8+fNr3mPgeh7BACRAWwDkXAPc/G1dIiIiIrsniTo2RKc5U6ZbxGfNgaxkYNR2oH4H61+PiIjIDpnz+7vG9bmxO+x3Q0REVK0YbqyNY90QERFVK4Yba+NYN0RERNWK4cba9E9MpSdWvB8RERFZBMONtfmEy8ub52xbDiIiojqC4cbafJvIy5vnAZ3WtmUhIiKqAxhurM0zBFA5AdpCIP2SrUtDRERk9xhurE2hAHwayevXz9q2LERERHUAw011qCdPDIobZ2xbDiIiojqA4aY66PvdXGe4ISIisjaGm+pQrzjc3GCzFBERkbUx3FQHX4YbIiKi6sJwUx18izsUZ6UABVm2LQsREZGdY7ipDs5egKufvM7aGyIiIqtiuKkuhk7FDDdERETWxHBTXfg4OBERUbVguKkufByciIioWjDcVBfD4+AMN0RERNbEcFNdDI+DnwN0OtuWhYiIyI4x3FQX71BAoQKKcoGsZFuXhoiIyG4x3FQXpQPgHS6vs98NERGR1TDcVCdOw0BERGR1DDfVybf4cXDW3BAREVkNw0114hNTREREVsdwU504SjEREZHVMdxUJ33NTUYSUJRn27IQERHZKYab6uTiCzh5AhDyeDdERERkcQw31UmSSgzmx343RERE1sBwYyFCCKRl5uPfKxkV78jHwYmIiKyK4cZCzl3LRucPt+HJb+IghCh/R8Pj4Aw3RERE1sBwYyENvF0AANkFGtzKLSp/Rz4OTkREZFUMNxbi5KBEgIcaAJB4M7f8HUs+Dl5RDQ8RERFVCsONBTX0kWtvKgw3PhEAJKAgA8i5Vj0FIyIiqkMYbiwopDjcJFUUbhycAK+G8jqnYSAiIrI4hhsLMtTc3Kgg3ADsd0NERGRFDDcWZFKzFFCi3w3DDRERkaUx3FiQyeGmXvHj4BzrhoiIyOIYbixIH25SMvJQqNGVvyNrboiIiKyG4caC/NzVUKsU0AkgOb2CiTH1fW5uXQQ0hdVSNiIiorqC4caCJEkyrWnKPQhwdAOEVg44REREZDE2DTezZ89Gp06d4O7uDn9/fwwZMgSnTp2q8JgdO3ZAkqRSr5MnT1ZTqStmUriRJMC3kbzOJ6aIiIgsyqbhZufOnRg3bhzi4uKwdetWaDQa9O3bFzk5OXc99tSpU0hJSTG8mjRpUg0lvjuTxroBgHpN5WVagpVLREREVLeobHnxTZs2Gb1funQp/P39cejQIXTv3r3CY/39/eHl5XXXaxQUFKCgoMDwPjMzs1JlNZXJT0wFtACO/QJc/deq5SEiIqpralSfm4yMDACAj4/PXfdt164dgoKC0Lt3b8TGxpa73+zZs+Hp6Wl4hYSEWKy8ZTE53AS2kpepDDdERESWVGPCjRACEyZMwH333YeWLVuWu19QUBC++eYbxMTEYM2aNYiMjETv3r2xa9euMvefMmUKMjIyDK+kpCRr3QIAoKHv7VGKRUUTYwYUh5ub54DCuwQhIiIiMplNm6VKGj9+PI4ePYo9e/ZUuF9kZCQiIyMN76Ojo5GUlIQ5c+aU2ZSlVquhVqstXt7yhHjL4SarQIOMvCJ4uTiWvaN7AODqJ0+emZYANOhQbWUkIiKyZzWi5ubll1/G+vXrERsbiwYNGph9fJcuXXDmTM146sjZUQk/dzlM3b3fTXEN1dVjVi4VERFR3WHTcCOEwPjx47FmzRps374d4eHhlTpPfHw8goKCLFy6yjO9301xuGG/GyIiIouxabPUuHHj8MMPP+C3336Du7s7UlNTAQCenp5wdnYGIPeZuXLlClasWAEAmDdvHsLCwtCiRQsUFhbi+++/R0xMDGJiYmx2H3dq6OOCQ5dumVBzU9zvhk9MERERWYxNw83ChQsBAD179jTavnTpUowcORIAkJKSgsTERMNnhYWFmDhxIq5cuQJnZ2e0aNECv//+OwYOHFhdxb4rk8e60dfcXD0OCCEP7kdERERVYtNwU+HTRMWWLVtm9H7SpEmYNGmSlUpkGabPDt4UUDoCBZlA+iXAO8z6hSMiIrJzNaJDsb0xOdwoHQC/4ie/2O+GiIjIIhhurEAfbpLT81Gk1VW8M/vdEBERWRTDjRX4u6vhqFJAqxNISc+veGfDE1N8HJyIiMgSGG6sQKGQEOItP+1l+lg3rLkhIiKyBIYbKzF7jqlbF4F8607qSUREVBcw3FiJyeHGxQdwD5bX005YuVRERET2j+HGSkwe6wZgvxsiIiILYrixEpNrboDbTVMMN0RERFXGcGMlDX3NCDfsVExERGQxDDdWEuIth5uMvCJk5BZVvLO+5ubqCUCntXLJiIiI7BvDjZW4qlWo5+YIAEi6dZfaG58IQOUMaPKAm+eroXRERET2i+HGikJM7XejUAIBUfI6+90QERFVCcONFZnVqZj9boiIiCyC4caKKvfEFMMNERFRVTDcWJFZY92w5oaIiMgiGG6syLxmqRbyMvMKkHvTiqUiIiKybww3VqQPN1du5UGj1VW8s5MH4BUqr7P2hoiIqNIYbqwowMMJjkoFNDqBlIz8ux/AfjdERERVxnBjRUqFhAbezgDY74aIiKi6MNxYmclj3QCcQJOIiMgCGG6srFJj3Vw7CWjvMmUDERERlYnhxsr04eaSKeHGKxRQewLaQiAtwcolIyIisk8MN1YW4ecKADh7NfvuOysUQHBbef3KIesVioiIyI4x3FhZZKA7AODctWwUau7yODgANOgoL68ctGKpiIiI7BfDjZXV93KGu1oFjU7g/HUTam/q68PNP9YtGBERkZ1iuLEySZLQtLj25lRq1t0PqN9BXqYlAAUm7E9ERERGGG6qgb5p6qQp4cY9APAMASCA5MNWLRcREZE9YripBpEBZtTcAED99vKS/W6IiIjMxnBTDSLNaZYCbve7ucxwQ0REZC6Gm2rQrDjcXEnPQ1a+CYPz6fvdsFMxERGR2RhuqoGXiyMCPNQAgNNXTai9CW4LSAogKxnITLZu4YiIiOwMw001iQz0AGBip2JHV8A/Sl7nYH5ERERmYbipJs3M7ndT3DTFfjdERERmYbipJvonpkyquQFK9LthzQ0REZE5GG6qScknpoQQdz9APw1Dcjyg01qxZERERPaF4aaaNPZ3g0ICMvKKcDWz4O4H+DUDHFyBwmzg2inrF5CIiMhOMNxUEycHJcLqyTOEnzLliSmFEghuJ6+zaYqIiMhkDDfV6Han4kzTDuBIxURERGZjuKlGkQFmPA4O3O53w5obIiIik9k03MyePRudOnWCu7s7/P39MWTIEJw6dff+JTt37kSHDh3g5OSEiIgILFq0qBpKW3WVnobh6gmgMNdKpSIiIrIvNg03O3fuxLhx4xAXF4etW7dCo9Ggb9++yMnJKfeYCxcuYODAgejWrRvi4+MxdepUvPLKK4iJianGkleOvlnqTFo2NFrd3Q/wCAbcAgGhBVKOWLl0RERE9kFly4tv2rTJ6P3SpUvh7++PQ4cOoXv37mUes2jRIjRs2BDz5s0DADRv3hwHDx7EnDlz8Oijj1q7yFXS0McFTg4K5BfpcPFGLhr7u1V8gCTJTVMnN8j9bkKjq6egREREtViN6nOTkZEBAPDx8Sl3n3379qFv375G2/r164eDBw+iqKj0pJQFBQXIzMw0etmKQiGhaYC5TVP6TsXsd0NERGSKGhNuhBCYMGEC7rvvPrRs2bLc/VJTUxEQEGC0LSAgABqNBtevXy+1/+zZs+Hp6Wl4hYSEWLzs5ogMMPeJqeJ+N5cZboiIiExRY8LN+PHjcfToUfz444933VeSJKP3+hF/79wOAFOmTEFGRobhlZSUZJkCV5KhU7EpY90AxWPdSEBGIpCdZr2CERER2YkaEW5efvllrF+/HrGxsWjQoEGF+wYGBiI1NdVoW1paGlQqFXx9fUvtr1ar4eHhYfSypWbFs4Ob3Czl5AH4RcrrbJoiIiK6K5uGGyEExo8fjzVr1mD79u0IDw+/6zHR0dHYunWr0bYtW7agY8eOcHBwsFZRLUZfc3PpZi5yCzWmHcQZwomIiExm03Azbtw4fP/99/jhhx/g7u6O1NRUpKamIi8vz7DPlClTMHz4cMP7MWPG4NKlS5gwYQISEhKwZMkSLF68GBMnTrTFLZjNz10NX1dHCAGcuZpt2kGGGcIZboiIiO7GpuFm4cKFyMjIQM+ePREUFGR4/fTTT4Z9UlJSkJiYaHgfHh6OjRs3YseOHWjbti1mzpyJ+fPn1/jHwEsyezC/Bp3k5eVDnCGciIjoLmw6zo2+I3BFli1bVmpbjx498M8//1ihRNUjMtAde8/dMH0ahoAWgKM7UJgFXD0OBLW2bgGJiIhqsRrRobiuMTwOftXEx8EVSiCks7yeGGelUhEREdmHSoUbrVaLOXPmoHPnzggMDISPj4/Riyp2u1nKxD43ANCweHTixH1WKBEREZH9qFS4mTFjBubOnYvHH38cGRkZmDBhAoYOHQqFQoHp06dbuIj2Rz9K8fXsAtzILjDtoIZd5GXiPsCE5jwiIqK6qlLhZtWqVfj2228xceJEqFQqPPXUU/juu+/w3nvvIS6OzSZ346pWoaGPCwBzpmHoAChUQFYKkJ549/2JiIjqqEqFm9TUVLRq1QoA4ObmZpgT6qGHHsLvv/9uudLZMf0M4ceTTex34+gCBLWV19nvhoiIqFyVCjcNGjRASkoKAKBx48bYsmULAODAgQNQq9WWK50daxPiBQCIT7pl+kElm6aIiIioTJUKN4888gi2bdsGAHj11Vfx7rvvokmTJhg+fDief/55ixbQXrVv6A0A+OdSuukHGToVs+aGiIioPJUa5+ajjz4yrD/22GNo0KAB9u7di8aNG+Phhx+2WOHsWZsQTygVElIz85GcnodgL+e7H6SvubmWAOTeBFz4ZBoREdGdLDKIX5cuXdClSxdLnKrOcHFUoVmgO44nZ+KfxFumhRvXeoBvE+DGGSBpPxDZ3/oFJSIiqmVMDjfr1683+aSsvTFN+4becri5lI6HWgebdlDDLnK4SdzHcENERFQGk8PNkCFDjN5LklRq+gRJkgDIg/zR3bUP9cLKuEv4J9GcTsXRQPxK9rshIiIqh8kdinU6neG1ZcsWtG3bFn/88QfS09ORkZGBP/74A+3bt8emTZusWV67ou9UfDw5A/lFJgZCfb+b5H+AonwrlYyIiKj2qlSfm9deew2LFi3CfffdZ9jWr18/uLi4YPTo0UhISLBYAe1ZQx8X+Lo64kZOIY4nZ6BDqAkdhH0iAFd/ICcNSI4HQqOtX1AiIqJapFKPgp87dw6enp6ltnt6euLixYtVLVOdIUkS2pn7SLgkcbwbIiKiClQq3HTq1AmvvfaaYSA/QB61+I033kDnzp0tVri6oH2oFwCY3+8GYL8bIiKiMlQq3CxZsgRpaWkIDQ1F48aN0bhxYzRs2BApKSlYvHixpcto1wyD+SXeKtVBu1z6pqikOECns1LJiIiIaqdK9blp3Lgxjh49iq1bt+LkyZMQQiAqKgp9+vQxPDFFpmndQB7M72pmAZIz8lHflPFuAloBDq5AfgZw7SQQEGX9ghIREdUSlR7ET5Ik9O3bF3379rVkeeocF0cVmge5498rmfjn0i3Two1SBYR0As7vkPvdMNwQEREZmBxu5s+fj9GjR8PJyQnz58+vcN9XXnmlygWrS9o39Ma/VzIRn5iOQW1MHcwvujjcxAGdXrBq+YiIiGoTk8PN//3f/2HYsGFwcnLC//3f/5W7nyRJDDdmat/QGyv2mTuYn/6JKXYqJiIiKsnkcHPhwoUy16nq7hzMz8lBefeD6ncEJCWQkQhkXAY8G1i5lERERLVDpZ6WIssK8XFGPTdHFGkFjidnmHaQ2g0Iai2vs/aGiIjIwOSamwkTJph80rlz51aqMHWVfjC/rSeu4p9L6aaNVAzI/W6S44GLe4BWj1m3kERERLWEyeEmPj7e6P2hQ4eg1WoRGRkJADh9+jSUSiU6dOhg2RLWEe314cacfjfhPYC4BXLHYiIiIgJgRriJjY01rM+dOxfu7u5Yvnw5vL3l/iK3bt3Cc889h27dulm+lHVA+4ZeAG4P5mfSeEFh9wIKFXDrAnDrIuAdZs0iEhER1QqV6nPz2WefYfbs2YZgAwDe3t744IMP8Nlnn1mscHVJ6wZeUJUYzM8kanegQSd5nbU3REREACoZbjIzM3H16tVS29PS0pCVlVXlQtVFzo5KNA/yAAD8c8mMpqmInvLyXGyFuxEREdUVlQo3jzzyCJ577jn8+uuvuHz5Mi5fvoxff/0VL7zwAoYOHWrpMtYZJZumTBbRS15e2Ml5poiIiFDJcLNo0SI8+OCDeOaZZxAaGorQ0FAMGzYMAwYMwIIFCyxdxjqjfah+Es100w+q3x5wdAfybgGpR6xTMCIiolrE7HCj1Wpx4MABfPDBB7hx4wbi4+Pxzz//4ObNm1iwYAFcXV2tUc46QT+Y34niwfxMonQAwos7cbPfDRERkfnhRqlUol+/fsjIyICrqytat26NNm3aMNRYQANvZwR4qFGkFex3Q0REVEmVapZq1aoVzp8/b+my1HmSJOHeRvUAAH+du276gfp+N4lxQFGeFUpGRERUe1Qq3MyaNQsTJ07Ehg0bkJKSgszMTKMXVV7XxnK42XP2hukH1WsCuAcD2gIgcZ+VSkZERFQ7mDyIX0n9+/cHADz88MNGg83pB5/Tak3sL0Kl3NvYFwBw7HI6MnKL4OnicPeDJAlo1As4vErud9PofusWkoiIqAarVLgpOVoxWVaQpzMa+bni3LUc7Dt/A/1bBpp2YERPOdyciwUesGoRiYiIarRKhZsePXpYuhxUwn2N6+HctRz8dfa6eeEGAFKPAjk3AFdfq5WPiIioJqtUnxsA2L17N5555hl07doVV65cAQCsXLkSe/bssVjh6qp7G1eiU7GbP+DfQl6/sMPyhSIiIqolTAo3f//9N4qKigzvY2Ji0K9fPzg7O+Off/5BQUEBACArKwsffvihdUpah9wT4QuFBJy/loPkdDOefmpU/NQUx7shIqI6zORw07dvX8O8UR988AEWLVqEb7/9Fg4Otzu8du3aFf/88491SlqHeDo7oHUDLwDAX2fNeSS8p7w8twMQwtLFIiIiqhVMCjevvPIKBg0ahJ49ewIATp06he7du5faz8PDA+np6ZYsX511n75pypxwE9oVUDgAGYnATY5DREREdZPJfW4mTJhgmDcqKCgIZ8+eLbXPnj17EBERYfLFd+3ahUGDBiE4OBiSJGHdunUV7r9jxw5IklTqdfLkSZOvWVvc7ndzA8LUWhhHVyDkHnn9PJ9oIyKiusmsDsX33CP/4vzvf/+LV199FX///TckSUJycjJWrVqFiRMnYuzYsSafLycnB23atMGXX35pVqFPnTqFlJQUw6tJkyZmHV8btA/1gpODAteyCnAmLdv0Axv1lJfsd0NERHVUpR4FnzRpEjIzM9GrVy/k5+eje/fuUKvVmDhxIsaPH2/yeQYMGIABAwaYfX1/f394eXmZfVxtolYp0SnMB7vPXMeeM9fRNMDdtAMjegHbPwAu7AJ0WkChtG5BiYiIahizam5yc3Mxbtw41K9fH9988w0GDRqEuLg4xMXF4dq1a5g5c6a1ymmkXbt2CAoKQu/eve86oGBBQUGtnR6iUv1ugtsBak8gPwO4ws7dRERU95gVbqZNm4Zly5bhwQcfxFNPPYXt27fj008/RefOneHm5matMhoEBQXhm2++QUxMDNasWYPIyEj07t0bu3btKveY2bNnw9PT0/AKCQmxejktRd/vJu78DRRpdaYdpFACjYunXzi9yUolIyIiqrkkYXJvVaBRo0aYNWsWnnzySQDA/v37ce+99yI/Px9KZdWaPyRJwtq1azFkyBCzjhs0aBAkScL69evL/LygoMAwDg8AZGZmIiQkBBkZGfDw8KhKka1OpxPo8MFW3MotQsxL0egQ6mPagUd+AtaOlgf1G7vXuoUkIiKqBpmZmfD09DTp97dZNTdJSUno1q2b4X3nzp2hUqmQnJxcuZJaQJcuXXDmzJlyP1er1fDw8DB61RYKhXR7lvAzZswS3uQBQFICaceBW5esVDoiIqKayaxwo9Vq4ejoaLRNpVJBo9FYtFDmiI+PR1BQkM2ub233NqpEvxsXH6BhtLzOpikiIqpjzHpaSgiBkSNHQq1WG7bl5+djzJgxcHV1NWxbs2aNSefLzs42Gi/nwoULOHz4MHx8fNCwYUNMmTIFV65cwYoVKwAA8+bNQ1hYGFq0aIHCwkJ8//33iImJQUxMjDm3UavoOxX/k3gLOQUauKpN/JFF9gcu7QFObQTu+a8VS0hERFSzmBVuRowYUWrbM888U+mLHzx4EL169TK8nzBhguE6y5YtQ0pKChITEw2fFxYWYuLEibhy5QqcnZ3RokUL/P777xg4cGCly1DTNfR1QYiPM5Ju5mH/hZvo1czftAMjBwJb3gEu/iU/OeXkad2CEhER1RBmdSi2B+Z0SKoppqw5ih/3J+HF+8LxzkNRph/4RUfgxhngsaVAy6HWKyAREZGVWa1DMdmG/pHwXWeumXdgZPEAiex3Q0REdQjDTS1wX+N6UCoknL6ajaSbuaYfaAg3mwGt7Tp9ExERVSeGm1rAy8URHUK9AQDbEq6afmCDzoCzD5CfDiT9bZ3CERER1TAMN7VEn+ZyR+JtJ9NMP0ipApr2k9dPbbRCqYiIiGoehptaonfzAADyVAxZ+UWmH9i0v7w89YcVSkVERFTzMNzUEo383BBezxVFWoHdZ8wY0K9xb0DpCNw8B1wvfyRnIiIie8FwU4v0Lh7j5k9z+t2o3YGw++R1Nk0REVEdwHBTi+ibpnacugatzozhiSKLBzk8xUfCiYjI/jHc1CIdw7zh4aTCzZxCxCfeMv1AfafipDgg96Z1CkdERFRDMNzUIg5KBXpG6pumzHhqyqshENAKEDrgzBYrlY6IiKhmYLipZXrrHwk3p98NcHtAP/a7ISIiO8dwU8v0bOoPpULCmbRsJN4wZ7Ti4kfCz24DivKsUzgiIqIagOGmlvF0cUCnMHm0YrOemgpuD3g0AAqz5YBDRERkpxhuaqE+xU9NbTtpRriRJCBqsLx+Yp3lC0VERFRDMNzUQvpHwv8+fxOZ5oxW3GKIvDy1CSjKt3zBiIiIagCGm1oovJ4rGvm5QqMT2HX6mukH1u8IeNQHCrOAc2yaIiIi+8RwU0sZmqbMeSRcoSjRNPWbFUpFRERkeww3tZS+aSr2VBo0Wp3pB0YNkZen/gA0BZYvGBERkY0x3NRS7Rt6wcvFAem5RfgnMd30Axt0AtyDgYJM4Nx2q5WPiIjIVhhuaimVUoFexaMVbz6eavqBCgUQ9bC8fnyd5QtGRERkYww3tdjAVkEAgP8dSTZvIk1D09RGNk0REZHdYbipxXo09YOnswPSsgoQd/6G6QeG3AO4BxU3TcVar4BEREQ2wHBTizmqFIbam3XxV0w/UKEAmhc3TXFAPyIisjMMN7XckLbBAIBN/6Yiv0hr+oH6Af1OsmmKiIjsC8NNLdcpzAfBnk7IKtBg+0kzxrwJ6QK4BQIFGcD5HVYrHxERUXVjuKnlFAoJD7etD6ASTVN8aoqIiOwQw40dGNJObpraceoaMnLNmGvK8NTU74Cm0PIFIyIisgGGGzvQLNADzQLdUajVYeO/KaYf2LAL4BYA5LNpioiI7AfDjZ0YXKmmKeXtp6b+jbFCqYiIiKofw42deLj4qam/L9xEcnqe6Qe2flxenlgH5N2yfMGIiIiqGcONnajv5YzO4T4AgPVHkk0/sEEnwD8K0OQDR3+xUumIiIiqD8ONHRlSmaYpSQI6jJTXDy0DhBnTOBAREdVADDd2ZGCrQDgoJZxMzcKp1CzTD2z9OKByAtKOA5cPWq+ARERE1YDhxo54uTiiR1N5pvDfDptRe+PsDbR4RF4/tMzyBSMiIqpGDDd2Rj/mzW+Hk6EzZ6ZwfdPU8TXyo+FERES1FMONnenTPABuahWupOdh/8Wbph8Ycg/g1wwoygWOsWMxERHVXgw3dsbJQYmHWsszhf90IMn0A0t2LD64jB2LiYio1mK4sUNPdAoBAGw8lmLedAytnwCUauDqMSD5HyuVjoiIyLoYbuxQ2xAvNAt0R4FGh3XmdCx28QGiBsvr7FhMRES1FMONHZIkCU8W1978uD8RwpwmJn3T1LEYoMCMx8mJiIhqCJuGm127dmHQoEEIDg6GJElYt27dXY/ZuXMnOnToACcnJ0RERGDRokXWL2gtNKRdfTiqFDiZmoWjl814+im0K+DbBCjKAY79ar0CEhERWYlNw01OTg7atGmDL7/80qT9L1y4gIEDB6Jbt26Ij4/H1KlT8corryAmhpM+3snLxREDWwYCAFYfSDT9wDtHLCYiIqplJGFWm4X1SJKEtWvXYsiQIeXuM3nyZKxfvx4JCQmGbWPGjMGRI0ewb9++Mo8pKChAQUGB4X1mZiZCQkKQkZEBDw8Pi5W/Jtp37gae+jYOro5K7H+7D1zVKtMOzLkBzG0GaAuBUbFA/fbWLSgREdFdZGZmwtPT06Tf37Wqz82+ffvQt29fo239+vXDwYMHUVRU9lNBs2fPhqenp+EVEhJSHUWtEbpE+CDM1wU5hVpsOGrGZJquvrdHLN75iXUKR0REZCW1KtykpqYiICDAaFtAQAA0Gg2uX79e5jFTpkxBRkaG4ZWUZMbYL7WcJEl4olNDAMCP+8287+5vApICOP0HkHTACqUjIiKyjloVbgD5F3ZJ+la1O7frqdVqeHh4GL3qksc6NIBKIeFwUjpOpmaafmC9JkCbp+X17TOtUzgiIiIrqFXhJjAwEKmpqUbb0tLSoFKp4Ovra6NS1Wx+7mr0aS7Xdq02t/amxyRA4QBc2Alc2GWF0hEREVlerQo30dHR2Lp1q9G2LVu2oGPHjnBwcLBRqWq+JzrL/YzWxl9BfpHW9AO9Q28/ObVtJqdkICKiWsGm4SY7OxuHDx/G4cOHAciPeh8+fBiJifKjy1OmTMHw4cMN+48ZMwaXLl3ChAkTkJCQgCVLlmDx4sWYOHGiLYpfa3Rv4odgTydk5BVh8/HUux9gdPBEQOUMXN4PnNlinQISERFZkE3DzcGDB9GuXTu0a9cOADBhwgS0a9cO7733HgAgJSXFEHQAIDw8HBs3bsSOHTvQtm1bzJw5E/Pnz8ejjz5qk/LXFkqFhP90lGtvfvjbjDFvAMA9EOg8Sl7fPhPQ6SxcOiIiIsuqMePcVBdznpO3J1fS89Dt4+3QCeD3V+5Di2BP0w/OvQnMaw0UZgH/WXb7MXEiIqJqYrfj3FDl1fdyxsBWQQCA73ZfMO9gFx8gepy8HvshoDOj3w4REVE1Y7ipQ0Z3jwAA/O9IMpLT88w7OHoc4OwNXD8NHP3JCqUjIiKyDIabOqR1Ay90ifCBRiew9C8za2+cPIB7X5PXd8wGNAUV7k5ERGQrDDd1zH+7NwIgj1icmV/2lBXl6jwacAsE0hOBuAVWKB0REVHVMdzUMT2a+qGJvxuyCzTmPznl6AI8MENe3/kpkJli+QISERFVEcNNHaNQSBhV3Pdm6V8XUKgx89HuVo8DDToBRTnAn9MtX0AiIqIqYripgwa3DYa/uxpXMwuw/ogZs4UDgEIBDPgYgAQcXQ0k/m2VMhIREVUWw00dpFYpMfLeMADAt7vOw+yhjup3ANoNk9f/mMSB/YiIqEZhuKmjht0TCldHJU5dzcLO09fMP0HvaYDaA0g5DBz+3uLlIyIiqiyGmzrK09kBT3ZuCAD4Ztd580/g5g/0mCyv/zkDyEu3XOGIiIiqgOGmDnvu3jAoFRL2nruBf69kmH+CzqOBek2B3OvAzk8sX0AiIqJKYLipwxp4u+Ch1vKUDF/FnjX/BCpHoP9seX3/10DaSQuWjoiIqHIYbuq4cb0aQyEBf/ybikOXbpl/gsZ9gMiBgE4D/DYOKMy1fCGJiIjMwHBTxzUNcMd/OoQAAD7cmGD+k1MA0O9DwMkTuHIQ+GUEoDVz5GMiIiILYrghvP5AUzg5KHDo0i1sPp5q/gl8woGnfwZUzsCZLXINDh8PJyIiG2G4IQR6OmFUN3nU4o83nUKRthLBpGEX4PHlgKSUZw3f8g5QmVogIiKiKmK4IQDAf3s0Qj03R1y4noMf95s555Re037A4K/k9bivgL/mWax8REREpmK4IQCAm1qFV/s0BQB8/ucZZJk7Y7he26eAvrPk9T+nA/+ssEwBiYiITMRwQwZPdgpBhJ8rbuQUYtHOc5U/UdfxwL2vyev/exU4+6dFykdERGQKhhsycFAqMLl/MwDAd7svICUjr/In6zMdaPsMIHTA2jFAdiWmeCAiIqoEhhsy0jcqAJ3CvFGg0WHultOVP5EkAQ9+BvhHATnXgPXj2cGYiIiqBcMNGZEkCVMHNgcA/PrP5cpNy6Dn4AQM/RZQOgKnNwEHl1iolEREROVjuKFS2jX0xqA2wRACmPDzYeQXaSt/ssCWchMVAGx+G7hWhdogIiIiEzDcUJmmD4pCPTc1Tl/NxpzNp6p2snteAiJ6Apo8YM2LgKbQImUkIiIqC8MNlcnXTY1PHmsFAPhuzwXsPXu98idTKIAhCwFnbyDlCLDjQwuVkoiIqDSGGyrX/c0C8PQ9DQEAb/xyBBl5VZgzyiMYGPS5vL5nHnBxT9ULSEREVAaGG6rQ2wObI8zXBSkZ+Xjvt3+rdrKowfLj4RDAmv8COVWoDSIiIioHww1VyFWtwv890RZKhYTfDidj/ZHkqp1wwEeAdziQeRlY9R+gINsyBSUiIirGcEN31a6hN8b1agwAeGftsaoN7qd2B4b9Ajj7AMn/AL+MALRVaO4iIiK6A8MNmeTl+xujTQNPZOZr8MbPR6CpzMzhevWaAE//DKic5akZ1r/MAf6IiMhiGG7IJA5KBeY+0RZODgrsPXcDU9Ycg6hKIAnpBDy+HJCUwJEfgW0zLFdYIiKq0xhuyGSN/NzwxVPtoVRI+OXQZXz0x8mqnbBpP+Dh+fL6nv8D4hZVvZBERFTnMdyQWR6ICsBHQ+Xxb77edb5qs4cDQLtngPvfldc3vQUc+7WKJSQiorqO4YbM9p+OIZg6UJ49/KM/TuLnA0lVO2G3N4BOowAIIOZFYPdc9sEhIqJKY7ihShndvRH+2yMCAPDWmqPYfDy18ieTJGDAx0DHFwAIuf9NzAtAYa5lCktERHUKww1V2lv9m+Hxjg2gE8DLP8Zj37kblT+ZQgk8NBd4cC6gUAH/xgBL+gHpVawVIiKiOofhhipNkiR8+Egr9I0KQKFGh9ErDuJ4ckbVTtrpBWD4esDFF0g9CnzTE7i01yLlJSKiuoHhhqpEpVRg/lPtcE+4D7IKNBix5AASb1SxOSnsXmD0DiCwFZB7HVj+MBC/yiLlJSIi+8dwQ1Xm5KDEN8M7olmgO65nF+DZJX/jWlZB1U7q1RB4fjPQ4hFAVwT8NlaecJMdjYmI6C5sHm4WLFiA8PBwODk5oUOHDti9e3e5++7YsQOSJJV6nTxZxfFWqMo8nR2w4vnOaODtjEs3cvHcsv3ILtBU7aSOrsBjS4F7X5Xf/zkN2PIOoKvC6MhERGT3bBpufvrpJ7z22mt4++23ER8fj27dumHAgAFITEys8LhTp04hJSXF8GrSpEk1lZgq4u/hhJUv3ANfV0f8eyUT/115EAUabdVOKknAA+8DfT+Q3+/7Elj3EuejIiKictk03MydOxcvvPACXnzxRTRv3hzz5s1DSEgIFi5cWOFx/v7+CAwMNLyUSmU1lZjuJryeK5Y+1wmujkr8dfYGJvx8BDqdBZqSur4MDFkkT9dwdDWw+mk+Kk5ERGWyWbgpLCzEoUOH0LdvX6Ptffv2xd69FT8d065dOwQFBaF3796IjY2tcN+CggJkZmYavci6WjfwwqJnO8BBKeH3oymY+MsRFFVlok29tk8BT/0oT7h5ZguwYjCQVYXxdYiIyC7ZLNxcv34dWq0WAQEBRtsDAgKQmlr2L6ygoCB88803iImJwZo1axAZGYnevXtj165d5V5n9uzZ8PT0NLxCQkIseh9Utm5N/PB/T7SFUiFhTfwVvPT9IeQXVbGJCpDnoxr+G+DkBVzeDyyIBk7+XvXzEhGR3ZBElaZ2rrzk5GTUr18fe/fuRXR0tGH7rFmzsHLlSpM7CQ8aNAiSJGH9+vVlfl5QUICCgttP7mRmZiIkJAQZGRnw8PCo2k3QXf154irG/fAPCjQ6dA73wXcjOsLDyaHqJ752Goh5Hkg9Jr/vMBLo96HcCZmIiOxOZmYmPD09Tfr9bbOam3r16kGpVJaqpUlLSytVm1ORLl264MyZM+V+rlar4eHhYfSi6tMnKgArnu8Md7UK+y/cxFPfxOF6dhUfEwcAv6bAi9vkvjgAcGgZ8HV3IDm+6ucmIqJazWbhxtHRER06dMDWrVuNtm/duhVdu3Y1+Tzx8fEICgqydPHIgu6J8MWPo7vA19URx5Mz8fiifbiSnlf1E6vU8lNUw38D3IOBG2eB7/oAu+bwaSoiojrMpk9LTZgwAd999x2WLFmChIQEvP7660hMTMSYMWMAAFOmTMHw4cMN+8+bNw/r1q3DmTNncPz4cUyZMgUxMTEYP368rW6BTNSyvid+GRON+l7OOH89B48u2IvDSemWOXlET+Clv4DmDwM6DbB9pjxtw+VDljk/ERHVKjYNN0888QTmzZuH999/H23btsWuXbuwceNGhIaGAgBSUlKMxrwpLCzExIkT0bp1a3Tr1g179uzB77//jqFDh9rqFsgMEX5u+PWlaDT2d0NqZj4eX7QPK+MuwSLdvlx8gMdXAI98DTj7AFf/Bb7rDfwxGSjIqvr5iYio1rBZh2JbMadDEllHZn4R3vzlCDYfvwoAeKRdfcx6pCVcHFWWuUDOdWDz2/J4OADgUR8YOAdoNtAy5yciompnzu9vhhuyCSEEvt19Hh9vOgWtTiAywB0Ln2mPCD83y13k3HZgw+vArYvy+8Z9gF5TgfodLHcNIiKqFgw3FWC4qVnizt/A+B/icT27AG5qFWYPbYVBbYItd4HCXGDnx8DeLwBRPM5Ok35Az7eA+u0tdx0iIrIqhpsKMNzUPGmZ+Rj/Qzz2X7wJAOjXIgDvD26JAA8ny13kxjlg92fAkdW3Q07TAUDPyUBwO8tdh4iIrILhpgIMNzVTkVaHL7adwYId56DRCbg7qTB1YHM80TEECoVkuQvdOAfs+hQ4+hMgiqeEiHxQrskJam256xARkUUx3FSA4aZmS0jJxFsxR3HkcgYAoEuED2YPbY3wehYeefj6WWDXJ8CxX26HnGYPAT2nAIEtLXstIiKqMoabCjDc1HxancDSvy7gsy2nkVekhVqlwLhejTG6ewScHCw8A/y108Uh51cAxX8Vmj8M9JjMkENEVIMw3FSA4ab2SLqZi6lrj2H3mesAgAbeznjnwSj0axEASbJgUxUApJ2UOx4fXwtDyAm5B2g/AmgxhHNWERHZGMNNBRhuahchBP53NAWzNyYgJSMfAHBvY19MG9QCTQPcLX/BtAQ55JxYf7vjsdoDaPUfoP1wILit5a9JRER3xXBTAYab2im3UIOFO87h613nUajRQamQ8GyXULzWpwm8XBwtf8GsVODwKuCfFbfHyQGAkC7yWDkRPSx/TSIiKhfDTQUYbmq3pJu5+OD3E4bRjT2cVHildxM8Gx0KtcrC/XEAQKcDLu4CDi0HTm4AtIXy9rBucsgJNX2SVyIiqjyGmwow3NiHPWeu44PfT+BkqjxvVIiPMyb3b4YHWwVZvj+OXmYKsOf/gENLb4eciF5yyAnpbJ1rEhERAIabCjHc2A+tTiDmn8v4bMspXM0sAAC0DfHCxL6R6NrI17Lj45SUcVkeEPCflYCuSN7m0whodL/8Cu8GqK3QH4iIqA5juKkAw439yS3U4LvdF7Bo5znkFsqdgOt7OeORdvXxSPv6aGTJ+apKunUJ2D0HOPwDoNPc3q5QyU9aNbofaD4I8Iu0zvWJiOoQhpsKMNzYr7SsfHy5/SzW/nMFWQW3w0abEC882r4+Hm4TbJ3Ox/mZwMXdwNlt8mSdty4Yf+7XTB47J+phIKAlYK1mMyIiO8ZwUwGGG/uXX6TF1hNXsTb+CnaevgatTv4jrlYp8FDrYAzr0hDtQrys1zfn5nk55Jz6Azi/83bTFQB4h8u1Oc0flmcnVyisUwYiIjvDcFMBhpu65VpWAdYfScYvB5MMnY8BICrIA8O6NMTgtvXhplZZrwB56cDpTfK4Oee2AZr825+5BQLNHgSaPyQ/faV0sF45iIhqOYabCjDc1E1CCMQnpWNVXCI2HE1GgUaeT8rVUYn7mwegX4sA9Iz0t27QKcgGzmyRHyk/vQUovB224OQpN195BAMe9YuXwYBXKBDYGlBasVxERLUAw00FGG4oPbcQvx66jB/+TsT56zmG7Y4qBbo1rod+LQPRp3kAfFyt0D9HT1MgN1md/B9wciOQe738fZ29gcYPAE37AY17y++JiOoYhpsKMNyQnr42Z/PxVGz+NxUXb+QaPpMkoHV9T3Rv6oduTfzQrqEXHJRW6h+j0wIpR4D0RCAzGci8UrxMBq6dBPLTb+8rKW8/iRXcTp4OwrWedcpFRFSDMNxUgOGGyiKEwKmrWdj871VsOp6KhJRMo8/d1CpEN/JF96Z+6NnUDyE+LtVTMK0GuHxA7rdzejNwLaH0Ph71gaC2ctDxawb4NgZ8wgEH5+opIxFRNWC4qQDDDZkiNSMfu89cw+4z17Hn7HXczCk0+ryRnyt6RvqjZ6QfOoX5wMnBClM/lOXWJbnfTmKcXNtz4ywMs5gbkQDPEMA3Qn5Cy9EVUDoCKvXtpasfEN4dcA+snrITEVUBw00FGG7IXDqdwImUTOw8fQ07T13DocRbhsfLAcDJQYE2DbzQPtQb7ULkZT03dfUULj8TSD0GpByWw871M8CNc0BBhunnCGgl9+Vp3FueGFRlxb5GRESVxHBTAYYbqqqMvCL8dfY6dpxKw45T15CWVVBqnxAfZ7Rv6I2OYT7oFOaNpv7u1psO4k5CALk35FqdG2flvjxFefJ8WJqC28sbZ+VQVJKjGxDURq7t8Q6Tm7e8wwHvUMDZh+PyEJHNMNxUgOGGLEkIgTNp2YhPvIV/LqUjPukWzqRl486/Ve5OKnQI9UanMB+0qu+Jxv5uCPJ0st5AgqbKvgacjy0eXXkbkHOt4v3VHvLLqXjp4iM/ru4dVuIVyv4+RGRxDDcVYLgha8vML8KRpHQcunQLhy7dwj+XbiGneM6rklwclYjwc0VjPzc08nNDkwA3NA1wR6ivK5TVVctTkk4HpB0H0k7KU0jcugjcLF5mJZt3LmdveewetYe81L9c6wHuQXI/H/3SLRBwcLLGHRGRHWG4qQDDDVU3jVaHk6lZOHjxJg5cuoVTqVm4eD0HGl3Zf/UcVQo08nNDZIAbmgS4IzLAHZGB7qjv5Vx9TVt30hTI/XsKMuVH0/XrOdfkTs6GMHTReHBCUzl5FQedgNtLN//iUOQlL531S285NNm61ouIqhXDTQUYbqgmKNLqkHgzF+fSsnHuWg7OpGXhbFo2Tl/NQn6RrsxjXByVaBLgjqb+bmjk74YQbxc08HZGA29n+Lg62r6JCyju73MTyEkrEYYybr9yrgFZKUBW6u1lySkpTCUpbwcd/csjCPBoAHjWlx+P92wg1w45ujIIEdkBhpsKMNxQTabTCVy+lYdTV7Nw+moWTqXKy/PXclCoLTv0AICzgxL1vZ0R6OGEem6O8HNXw89djXpuasO6n5sa3i6Otqv9KYsQck1Q1lUgO9V4mXOtRDBKl+fpyk83Pwwp1XLfIGef4qV3ife+8rqLr7xd6QBAAiRFcSCS5G0u9eTP2aGayGYYbirAcEO1kUarw8UbuTh9NQsnU7Nw6UYOrtzKw+VbebialV+qA3N5lArJEH4C3J0Q4qOv/XFBiI8zQnxc4OFUwyfwLMovDju3br9ybwCZKUBGkjzCc8YVeVmYbbnrSkq5z5CrP+DmJ4cdlbM8ZpDKSe43pHKSw5JHfbnWyCNYDkYMRURVxnBTAYYbsjcFGi1S0vNx+VYe0rLycT27ANeyCnA9uxDXsuT1a9kFpQYiLI+zgxKezg7wcnEwWno6O8DDyQEezg7wcFbBw0n/uSN8XB3h6exgm47Q5RECKMwB8m7K4Sf3ZnEQulm87Wbpz3Qa+TgIQOjkdW2h8RQY5lI4yP2IHN3kJjJHF8CheCkpi5vuipvv9Osqx9v9joyWAfLgi/ptzt5scqM6g+GmAgw3VFcVaXW4oQ882flIychH0s08JN3KxeWbuUi6lWdyACqLJAGezg7wcXGEl4sDfFwdDcHHy8UB3i6O8HKWw9HtoKSCu1MNC0Vl0RTKk5tmp8nNZdlpchjR5MudrTX58qsoD8i5Lj9dlpks71fmCNIWonCQm9QcnOWXyqmMpZNcw+TgBDi4yM1sCgd5qXQEFCp5XVJAbpKTbq+r1HKIcvWTX2p34zBVmCuHw7yb8vehdpdrqlz9+AQcWZw5v79V1VQmIrIxB6UCgZ5OCPR0AuBZ5j45BRrczClEem4R0vPkZUZeEdJzC5GVr0Fmvvw+M09eT88twq3iz4SAfFxukdllc3VUwlWtgpuTCu7FS2cHJQAJCglQSBKk4qW7k8qoH5G+b5GHswNc1UqoVVaYCkPlKDcxeQSbd5y2SO40nX1VbiIrzJVrk4py5HWhNR43yMlLXtfky8dkp91eZqXeDlbZV+XaJF2R3Eepuqic5eAitHJtlyav/H0d3eRmPBff4vGR3Ivv0/P2un6IAMOQAR5y8NLTBylJUVzz5cYmPjIJa26IqMqKtDpk5BXhVk4hbuYU4lauHIhu5hbiVvH7WzmFcjAqEZDyikqP/1NVDkoJrmoVXB1VcFOr4KJWwtVRBZfiAOXsqISzgxJODgo4qZRwKl5Xq5RQKm6HKEkCJEmCSiEHKn0znIezA9ydVNabJd5UmgI57OTekPshafKMl0W5t2uTSi61hfKErNpCORxpi18QcjOc0N1eL8qTn3zLviYHsrLoa4+cPICCLLnmSmd+wDWZo5scjhzdimuHpNudv0t2AjfMpaaWw6lSLW/Xz6+mf6nUt2u+HFxKLx1djZcqNZsCbYQ1N0RUrRyUCtRzU5s9p1ahRofM/CLkFGiQla9BdoEG2cXLvCKt/LsWAjoBQMjLjLwio75E+nV9UCrSikrXIJnDUamAUiFBqZBrl1RKBRSSBFe10hCG9Es3J5Vhf5VCglKhgEopr7s4KuHsqIKroxLOjkq4OKrgqFIU73f7pVJIcHa4vY9SpZYfd/dsYNX7NCjMud0sp1AWP2nmK4eMkr/shZCbqHJvyEEn94Ycegoyb/cpMlrqn4grXhfa2+fR02luby/MtmxHcbNJpUOQIfDcEbQUDrfDk6GpsLgDuj5YGQKYukSToWNxQCu5XiKg6Y8tGbwU1TR5by3BcENENuOoqlwoKotGq0NOoRY5BRo5LBUvcwu1yCvUIqdQIy8LtMgr0iK/SIsCjRb5RTrkFWqRr9FCJ+QpNYQAdMXLIq0O2QUaZObJNU760aYLtTqgjIqn69X0e9dRpYCLoxIuDko4qhRwVCngoJSXjsVLtcr4vaNKrq1ydpRrrNQqBZwd5aa8ks1/gFxrpY8scrYUABwB1IeTgxIe+Q7wzBPwcM6Dh7MD3BxV8jADkiQPuOjsBfg2sszNCiHXVBVkyYNEFhS/NPnFhStR2wRRXBtVWHo+Nf02baHcj0pbaNxfqij39rIwt3iZIy+1+v5oQq7FKq8my1aUxSFKH4YUSjkoKVTyuk5T4qWVl5ISUBc396ndAEd3eakPX/pzqdQlmguLQ6c+fCoUxSGv+OVYHPjUHkBIZ5t8FQDDDRHZCZVSAU9nBTydrfsou0arQ1a+BrlFWuh0AlqdgFbIS41WIK9IY+iTlJkvh6LsAg00Wh00xftrdAJarUChVofcwtsBLLdQi9xCDYq0t/fTCQGNVgetTiCvSA5ggFzrVajRIR3WraEylSQBKoUESZKglIxrtJxUCjg5KksEKwVUCoXc9IfbQUqSYAhg6uKmQn0Ik8ObBJVCAQeVFxyV3lAZasDkpYNSrhVzUEtQF4c9/ctRWbyvUipel2vHHJUK08Z+0mqKQ01+iRCUd7v5z/CUXfESkEOWITyVaDLUFhR3RC8oXi+Ul/omQm2hHD4MYazIeF3fib0wp8S1is9lrkoMKG4SVz/gzbNWOvndMdwQEZlBpVTA29UR3ja4thACBRqdUU1UXpHWEHQKtPKyqHhZqNGhsHi9wPDSIr+wuMaqSD6+QKMz1FgJFC+L12/X38jhQwggX6O93bE8rwiFWl1xLVeJX+y1iCQBDoaAJIeo28FIgqNKCcfibSWbChWSBKXCCUqFM1QKCSqlAg4KOUApFSXCWHGo0q8rlQo4OEqGYwzHKm83QaoUCiiLmy6VkgRFyWbK4vDooJDggAI4agvgoMuDSpsHBTRQCi0UOi0kUQSF0EIhdFCoHKBUOUBhqNVRyX2jCoqb+Qqyi2vFskvXculfkG5/YfKKHMIMQS9HXhbmyjV3NsRwQ0RUS0iSVNwBWglvV0dbF8cgv0iLzPwiuRZLJ6DTyc16WiHXZhVotMVNf8VNgEVaFGl1cgwqGaiA4iAmh6/84uCVX6SFRitQpNWhSCdQpNFBo9OhUCvXamm0AkU6nWEfja54X428jz7saXS64gBmTAi5mVFucbR8J/eaQX6yTZJgCEe3w5UKKqU3VApfQ18wlaK4j5jSOFDd2Q9Moa+lU0hQOEjy6ALuErycHfGeDe+W4YaIiKpEH7hqAyFuN/kVlQhGRcVBqUgroCkOSgXFtWD6lxyQigOcENDq5ClT5G23jzU0KxaHsTvPK39++zO5DPI2TfGxJd/rhP6agEang06HEueSy6S/j7s9/ywEoBFymeVGLOuEOX93Nd4bFGWVc5uC4YaIiOoMSSpuIlKi1gQyc4jipwr1gUgIGPqEyaFOZ+gfpg95mhKhyni9xD5a3R3nEYZgVzJ86Yr7oDnb+Lu1ebhZsGABPv30U6SkpKBFixaYN28eunXrVu7+O3fuxIQJE3D8+HEEBwdj0qRJGDNmTDWWmIiIqGaSO3QDSkiww+xmMpuOQvXTTz/htddew9tvv434+Hh069YNAwYMQGJiYpn7X7hwAQMHDkS3bt0QHx+PqVOn4pVXXkFMTEw1l5yIiIhqKpuOUHzPPfegffv2WLhwoWFb8+bNMWTIEMyePbvU/pMnT8b69euRkJBg2DZmzBgcOXIE+/btM+maHKGYiIio9jHn97fNam4KCwtx6NAh9O3b12h73759sXfv3jKP2bdvX6n9+/Xrh4MHD6KoqOyxHgoKCpCZmWn0IiIiIvtls3Bz/fp1aLVaBAQEGG0PCAhAamrZE8GlpqaWub9Go8H169fLPGb27Nnw9PQ0vEJCQixzA0RERFQj2Xx6VemOCciEEKW23W3/srbrTZkyBRkZGYZXUlJSFUtMRERENZnNnpaqV68elEplqVqatLS0UrUzeoGBgWXur1Kp4OvrW+YxarUaanXV560hIiKi2sFmNTeOjo7o0KEDtm7darR969at6Nq1a5nHREdHl9p/y5Yt6NixIxwcrDufDBEREdUONm2WmjBhAr777jssWbIECQkJeP3115GYmGgYt2bKlCkYPny4Yf8xY8bg0qVLmDBhAhISErBkyRIsXrwYEydOtNUtEBERUQ1j00H8nnjiCdy4cQPvv/8+UlJS0LJlS2zcuBGhoaEAgJSUFKMxb8LDw7Fx40a8/vrr+OqrrxAcHIz58+fj0UcftdUtEBERUQ1j03FubIHj3BAREdU+tWKcGyIiIiJrYLghIiIiu8JwQ0RERHbF5rOCVzd9FyNOw0BERFR76H9vm9JVuM6Fm6ysLADgNAxERES1UFZWFjw9PSvcp849LaXT6ZCcnAx3d/cKp3mojMzMTISEhCApKclun8TiPdoH3qN94D3ah7pwj0DV71MIgaysLAQHB0OhqLhXTZ2ruVEoFGjQoIFVr+Hh4WHXf0AB3qO94D3aB96jfagL9whU7T7vVmOjxw7FREREZFcYboiIiMiuMNxYkFqtxrRp0+x6FnLeo33gPdoH3qN9qAv3CFTvfda5DsVERERk31hzQ0RERHaF4YaIiIjsCsMNERER2RWGGyIiIrIrDDdERERkVxhuLGTBggUIDw+Hk5MTOnTogN27d9u6SFWya9cuDBo0CMHBwZAkCevWrTP6XAiB6dOnIzg4GM7OzujZsyeOHz9um8JWwuzZs9GpUye4u7vD398fQ4YMwalTp4z2qe33uHDhQrRu3dowGmh0dDT++OMPw+e1/f7KMnv2bEiShNdee82wzR7uc/r06ZAkyegVGBho+Nwe7hEArly5gmeeeQa+vr5wcXFB27ZtcejQIcPntf0+w8LCSv0cJUnCuHHjANT++wMAjUaDd955B+Hh4XB2dkZERATef/996HQ6wz7Vcp+Cqmz16tXCwcFBfPvtt+LEiRPi1VdfFa6uruLSpUu2Llqlbdy4Ubz99tsiJiZGABBr1641+vyjjz4S7u7uIiYmRhw7dkw88cQTIigoSGRmZtqmwGbq16+fWLp0qfj333/F4cOHxYMPPigaNmwosrOzDfvU9ntcv369+P3338WpU6fEqVOnxNSpU4WDg4P4999/hRC1//7utH//fhEWFiZat24tXn31VcN2e7jPadOmiRYtWoiUlBTDKy0tzfC5PdzjzZs3RWhoqBg5cqT4+++/xYULF8Sff/4pzp49a9intt9nWlqa0c9w69atAoCIjY0VQtT++xNCiA8++ED4+vqKDRs2iAsXLohffvlFuLm5iXnz5hn2qY77ZLixgM6dO4sxY8YYbWvWrJl46623bFQiy7oz3Oh0OhEYGCg++ugjw7b8/Hzh6ekpFi1aZIMSVl1aWpoAIHbu3CmEsM97FEIIb29v8d1339nd/WVlZYkmTZqIrVu3ih49ehjCjb3c57Rp00SbNm3K/Mxe7nHy5MnivvvuK/dze7nPkl599VXRqFEjodPp7Ob+HnzwQfH8888bbRs6dKh45plnhBDV93Nks1QVFRYW4tChQ+jbt6/R9r59+2Lv3r02KpV1XbhwAampqUb3rFar0aNHj1p7zxkZGQAAHx8fAPZ3j1qtFqtXr0ZOTg6io6Pt7v7GjRuHBx98EH369DHabk/3eebMGQQHByM8PBxPPvkkzp8/D8B+7nH9+vXo2LEj/vOf/8Df3x/t2rXDt99+a/jcXu5Tr7CwEN9//z2ef/55SJJkN/d33333Ydu2bTh9+jQA4MiRI9izZw8GDhwIoPp+jnVuVnBLu379OrRaLQICAoy2BwQEIDU11Ualsi79fZV1z5cuXbJFkapECIEJEybgvvvuQ8uWLQHYzz0eO3YM0dHRyM/Ph5ubG9auXYuoqCjDPyK1/f4AYPXq1fjnn39w4MCBUp/Zy8/xnnvuwYoVK9C0aVNcvXoVH3zwAbp27Yrjx4/bzT2eP38eCxcuxIQJEzB16lTs378fr7zyCtRqNYYPH24396m3bt06pKenY+TIkQDs58/q5MmTkZGRgWbNmkGpVEKr1WLWrFl46qmnAFTffTLcWIgkSUbvhRClttkbe7nn8ePH4+jRo9izZ0+pz2r7PUZGRuLw4cNIT09HTEwMRowYgZ07dxo+r+33l5SUhFdffRVbtmyBk5NTufvV9vscMGCAYb1Vq1aIjo5Go0aNsHz5cnTp0gVA7b9HnU6Hjh074sMPPwQAtGvXDsePH8fChQsxfPhww361/T71Fi9ejAEDBiA4ONhoe22/v59++gnff/89fvjhB7Ro0QKHDx/Ga6+9huDgYIwYMcKwn7Xvk81SVVSvXj0olcpStTRpaWmlkqm90D+lYQ/3/PLLL2P9+vWIjY1FgwYNDNvt5R4dHR3RuHFjdOzYEbNnz0abNm3w+eef2839HTp0CGlpaejQoQNUKhVUKhV27tyJ+fPnQ6VSGe6ltt/nnVxdXdGqVSucOXPGbn6WQUFBiIqKMtrWvHlzJCYmArCfv5MAcOnSJfz555948cUXDdvs5f7efPNNvPXWW3jyySfRqlUrPPvss3j99dcxe/ZsANV3nww3VeTo6IgOHTpg69atRtu3bt2Krl272qhU1hUeHo7AwECjey4sLMTOnTtrzT0LITB+/HisWbMG27dvR3h4uNHn9nCPZRFCoKCgwG7ur3fv3jh27BgOHz5seHXs2BHDhg3D4cOHERERYRf3eaeCggIkJCQgKCjIbn6W9957b6nhGE6fPo3Q0FAA9vV3cunSpfD398eDDz5o2GYv95ebmwuFwjhaKJVKw6Pg1XafFuuaXIfpHwVfvHixOHHihHjttdeEq6uruHjxoq2LVmlZWVkiPj5exMfHCwBi7ty5Ij4+3vB4+0cffSQ8PT3FmjVrxLFjx8RTTz1Vqx5ZfOmll4Snp6fYsWOH0aOZubm5hn1q+z1OmTJF7Nq1S1y4cEEcPXpUTJ06VSgUCrFlyxYhRO2/v/KUfFpKCPu4zzfeeEPs2LFDnD9/XsTFxYmHHnpIuLu7G/6NsYd73L9/v1CpVGLWrFnizJkzYtWqVcLFxUV8//33hn3s4T61Wq1o2LChmDx5cqnP7OH+RowYIerXr294FHzNmjWiXr16YtKkSYZ9quM+GW4s5KuvvhKhoaHC0dFRtG/f3vBIcW0VGxsrAJR6jRgxQgghP843bdo0ERgYKNRqtejevbs4duyYbQtthrLuDYBYunSpYZ/afo/PP/+84c+kn5+f6N27tyHYCFH77688d4Ybe7hP/TggDg4OIjg4WAwdOlQcP37c8Lk93KMQQvzvf/8TLVu2FGq1WjRr1kx88803Rp/bw31u3rxZABCnTp0q9Zk93F9mZqZ49dVXRcOGDYWTk5OIiIgQb7/9tigoKDDsUx33KQkhhOXqgYiIiIhsi31uiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2RWGGyIiIrIrDDdEZFNnzpzBnDlzDMOzExFVFcMNEdmMTqfD8OHDUb9+/VLz0RARVRZHKCYimzlz5gx2796N559/3tZFISI7wnBDREREdoX1wERU7UaOHAlJkkq9+vfvb+uiEZEdUNm6AERUN/Xv3x9Lly412qZWq21UGiKyJ6y5ISKbUKvVCAwMNHp5e3sDACRJwsKFCzFgwAA4OzsjPDwcv/zyi9Hxx44dw/333w9nZ2f4+vpi9OjRyM7ONtpnyZIlaNGiBdRqNYKCgjB+/HjDZ3PnzkWrVq3g6uqKkJAQjB071uj4S5cuYdCgQfD29oarqytatGiBjRs3WvEbISJLYbghohrp3XffxaOPPoojR47gmWeewVNPPYWEhAQAQG5uLvr37w9vb28cOHAAv/zyC/7880+j8LJw4UKMGzcOo0ePxrFjx7B+/Xo0btzY8LlCocD8+fPx77//Yvny5di+fTsmTZpk+HzcuHEoKCjArl27cOzYMXz88cdwc3Orvi+AiCpPEBFVsxEjRgilUilcXV2NXu+//74QQggAYsyYMUbH3HPPPeKll14SQgjxzTffCG9vb5GdnW34/PfffxcKhUKkpqYKIYQIDg4Wb7/9tsll+vnnn4Wvr6/hfatWrcT06dMrfY9EZDvsc0NENtGrVy8sXLjQaJuPj49hPTo62uiz6OhoHD58GACQkJCANm3awNXV1fD5vffeC51Oh1OnTkGSJCQnJ6N3797lXj82NhYffvghTpw4gczMTGg0GuTn5yMnJweurq545ZVX8NJLL2HLli3o06cPHn30UbRu3doCd05E1sZmKSKyCVdXVzRu3NjoVTLclEWSJACAEMKwXtY+zs7OFZ7n0qVLGDhwIFq2bImYmBgcOnQIX331FQCgqKgIAPDiiy/i/PnzePbZZ3Hs2DF07NgRX3zxhbm3SUQ2wHBDRDVSXFxcqffNmjUDAERFReHw4cPIyckxfP7XX39BoVCgadOmcHd3R1hYGLZt21bmuQ8ePAiNRoPPPvsMXbp0QdOmTZGcnFxqv5CQEIwZMwZr1qzBG2+8gW+//daCd0hE1sJmKSKyiYKCAqSmphptU6lUqFevHgDgl19+QceOHXHfffdh1apV2L9/PxYvXgwAGDZsGKZNm4YRI0Zg+vTpuHbtGl5++WU8++yzCAgIAABMnz4dY8aMgb+/PwYMGICsrCz89ddfePnll9GoUSNoNBp88cUXGDRoEP766y8sWrTIqCyvvfYaBgwYgKZNm+LWrVvYvn07mjdvXg3fDBFVma07/RBR3TNixAgBoNQrMjJSCCF3KP7qq6/EAw88INRqtQgNDRU//vij0TmOHj0qevXqJZycnISPj48YNWqUyMrKMtpn0aJFIjIyUjg4OIigoCDx8ssvGz6bO3euCAoKEs7OzqJfv35ixYoVAoC4deuWEEKI8ePHi0aNGgm1Wi38/PzEs88+K65fv27dL4aILILTLxBRjSNJEtauXYshQ4bYuihEVAuxzw0RERHZFYYbIiIisivsUExENQ5by4moKlhzQ0RERHaF4YaIiIjsCsMNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu/L/S4pQGEywARMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape de X_train y X_test para que tenga el formato adecuado: (samples, time steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Crear el modelo RNN con una sola capa\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(12, input_shape=(X_train.shape[1], 1)))  # 50 neuronas en la capa RNN\n",
    "model.add(Dense(1))  # Una salida\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train, epochs=80, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss}\")\n",
    "\n",
    "# Graficar la historia del entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en validación')\n",
    "plt.title('Historia del entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesita unas 15 etapas la red con una sola capa recurrente para estabilizar su grafica de pérdidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO CON MÁS CAPAS RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 3.6534 - val_loss: 3.5040\n",
      "Epoch 2/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2612 - val_loss: 2.6270\n",
      "Epoch 3/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7487 - val_loss: 2.1326\n",
      "Epoch 4/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5638 - val_loss: 1.7963\n",
      "Epoch 5/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1900 - val_loss: 1.5313\n",
      "Epoch 6/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0612 - val_loss: 1.2851\n",
      "Epoch 7/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7665 - val_loss: 1.0755\n",
      "Epoch 8/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5841 - val_loss: 0.8959\n",
      "Epoch 9/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6365 - val_loss: 0.7451\n",
      "Epoch 10/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4478 - val_loss: 0.6325\n",
      "Epoch 11/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3896 - val_loss: 0.5439\n",
      "Epoch 12/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3993 - val_loss: 0.4735\n",
      "Epoch 13/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2802 - val_loss: 0.4178\n",
      "Epoch 14/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2985 - val_loss: 0.3752\n",
      "Epoch 15/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2388 - val_loss: 0.3447\n",
      "Epoch 16/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2791 - val_loss: 0.3191\n",
      "Epoch 17/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2594 - val_loss: 0.2974\n",
      "Epoch 18/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2095 - val_loss: 0.2816\n",
      "Epoch 19/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1936 - val_loss: 0.2661\n",
      "Epoch 20/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1876 - val_loss: 0.2530\n",
      "Epoch 21/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1470 - val_loss: 0.2451\n",
      "Epoch 22/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1648 - val_loss: 0.2353\n",
      "Epoch 23/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1589 - val_loss: 0.2267\n",
      "Epoch 24/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1468 - val_loss: 0.2202\n",
      "Epoch 25/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1348 - val_loss: 0.2144\n",
      "Epoch 26/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1414 - val_loss: 0.2090\n",
      "Epoch 27/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1231 - val_loss: 0.2022\n",
      "Epoch 28/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1298 - val_loss: 0.1973\n",
      "Epoch 29/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1477 - val_loss: 0.1905\n",
      "Epoch 30/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1350 - val_loss: 0.1878\n",
      "Epoch 31/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0980 - val_loss: 0.1786\n",
      "Epoch 32/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0975 - val_loss: 0.1750\n",
      "Epoch 33/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1129 - val_loss: 0.1729\n",
      "Epoch 34/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0994 - val_loss: 0.1621\n",
      "Epoch 35/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0991 - val_loss: 0.1564\n",
      "Epoch 36/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0877 - val_loss: 0.1473\n",
      "Epoch 37/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1143 - val_loss: 0.1412\n",
      "Epoch 38/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.1410\n",
      "Epoch 39/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1048 - val_loss: 0.1319\n",
      "Epoch 40/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0703 - val_loss: 0.1297\n",
      "Epoch 41/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0764 - val_loss: 0.1305\n",
      "Epoch 42/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0677 - val_loss: 0.1260\n",
      "Epoch 43/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0675 - val_loss: 0.1256\n",
      "Epoch 44/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0863 - val_loss: 0.1194\n",
      "Epoch 45/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.1196\n",
      "Epoch 46/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0531 - val_loss: 0.1155\n",
      "Epoch 47/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0651 - val_loss: 0.1205\n",
      "Epoch 48/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0641 - val_loss: 0.1181\n",
      "Epoch 49/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0584 - val_loss: 0.1149\n",
      "Epoch 50/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0525 - val_loss: 0.1141\n",
      "Epoch 51/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0666 - val_loss: 0.1166\n",
      "Epoch 52/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0579 - val_loss: 0.1077\n",
      "Epoch 53/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0578 - val_loss: 0.1148\n",
      "Epoch 54/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0487 - val_loss: 0.1060\n",
      "Epoch 55/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0537 - val_loss: 0.1091\n",
      "Epoch 56/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0578 - val_loss: 0.1037\n",
      "Epoch 57/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0450 - val_loss: 0.1007\n",
      "Epoch 58/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0508 - val_loss: 0.1038\n",
      "Epoch 59/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0606 - val_loss: 0.1024\n",
      "Epoch 60/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0500 - val_loss: 0.1001\n",
      "Epoch 61/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0476 - val_loss: 0.1016\n",
      "Epoch 62/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0601 - val_loss: 0.0988\n",
      "Epoch 63/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0373 - val_loss: 0.0969\n",
      "Epoch 64/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0453 - val_loss: 0.0980\n",
      "Epoch 65/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0470 - val_loss: 0.0955\n",
      "Epoch 66/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0426 - val_loss: 0.0931\n",
      "Epoch 67/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0360 - val_loss: 0.0963\n",
      "Epoch 68/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0448 - val_loss: 0.0936\n",
      "Epoch 69/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0392 - val_loss: 0.0898\n",
      "Epoch 70/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0445 - val_loss: 0.0919\n",
      "Epoch 71/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0433 - val_loss: 0.0889\n",
      "Epoch 72/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0414 - val_loss: 0.0866\n",
      "Epoch 73/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0348 - val_loss: 0.0923\n",
      "Epoch 74/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0394 - val_loss: 0.0863\n",
      "Epoch 75/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0426 - val_loss: 0.0848\n",
      "Epoch 76/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0527 - val_loss: 0.0856\n",
      "Epoch 77/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0402 - val_loss: 0.0857\n",
      "Epoch 78/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0356 - val_loss: 0.0802\n",
      "Epoch 79/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0412 - val_loss: 0.0811\n",
      "Epoch 80/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0424 - val_loss: 0.0806\n",
      "Epoch 81/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0357 - val_loss: 0.0790\n",
      "Epoch 82/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0351 - val_loss: 0.0776\n",
      "Epoch 83/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0490 - val_loss: 0.0763\n",
      "Epoch 84/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0408 - val_loss: 0.0744\n",
      "Epoch 85/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0370 - val_loss: 0.0742\n",
      "Epoch 86/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0780\n",
      "Epoch 87/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0349 - val_loss: 0.0762\n",
      "Epoch 88/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0397 - val_loss: 0.0719\n",
      "Epoch 89/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0370 - val_loss: 0.0702\n",
      "Epoch 90/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0702\n",
      "Epoch 91/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0318 - val_loss: 0.0693\n",
      "Epoch 92/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0315 - val_loss: 0.0684\n",
      "Epoch 93/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0382 - val_loss: 0.0678\n",
      "Epoch 94/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0271 - val_loss: 0.0711\n",
      "Epoch 95/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0325 - val_loss: 0.0654\n",
      "Epoch 96/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0258 - val_loss: 0.0658\n",
      "Epoch 97/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0383 - val_loss: 0.0656\n",
      "Epoch 98/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0316 - val_loss: 0.0643\n",
      "Epoch 99/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0624\n",
      "Epoch 100/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0633\n",
      "Epoch 101/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0296 - val_loss: 0.0673\n",
      "Epoch 102/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0332 - val_loss: 0.0620\n",
      "Epoch 103/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - val_loss: 0.0596\n",
      "Epoch 104/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - val_loss: 0.0593\n",
      "Epoch 105/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0276 - val_loss: 0.0588\n",
      "Epoch 106/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0590\n",
      "Epoch 107/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0279 - val_loss: 0.0571\n",
      "Epoch 108/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0564\n",
      "Epoch 109/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0264 - val_loss: 0.0570\n",
      "Epoch 110/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0345 - val_loss: 0.0538\n",
      "Epoch 111/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0564\n",
      "Epoch 112/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0333 - val_loss: 0.0569\n",
      "Epoch 113/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0275 - val_loss: 0.0554\n",
      "Epoch 114/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0268 - val_loss: 0.0522\n",
      "Epoch 115/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - val_loss: 0.0508\n",
      "Epoch 116/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0274 - val_loss: 0.0505\n",
      "Epoch 117/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - val_loss: 0.0520\n",
      "Epoch 118/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0287 - val_loss: 0.0488\n",
      "Epoch 119/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0336 - val_loss: 0.0496\n",
      "Epoch 120/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0347 - val_loss: 0.0499\n",
      "Epoch 121/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0346 - val_loss: 0.0476\n",
      "Epoch 122/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0476\n",
      "Epoch 123/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0277 - val_loss: 0.0457\n",
      "Epoch 124/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0448\n",
      "Epoch 125/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0232 - val_loss: 0.0451\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0389\n",
      "Pérdida en el conjunto de prueba: 0.0451187901198864\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo RNN con múltiples capas\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa RNN con return_sequences=True\n",
    "model.add(SimpleRNN(12, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Segunda capa RNN con return_sequences=True\n",
    "model.add(SimpleRNN(12, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(SimpleRNN(12, return_sequences=False))  # Última capa sin return_sequences\n",
    "\n",
    "# Capa de salida\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train, epochs=125, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en validación')\n",
    "plt.title('Historia del entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendimiento ha mejorado significativamente añadiendo más capas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO CON UNA CAPA LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.6870 - val_loss: 6.1243\n",
      "Epoch 2/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4651 - val_loss: 5.5009\n",
      "Epoch 3/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1193 - val_loss: 4.8961\n",
      "Epoch 4/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2096 - val_loss: 4.3132\n",
      "Epoch 5/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1708 - val_loss: 3.7475\n",
      "Epoch 6/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7144 - val_loss: 3.2237\n",
      "Epoch 7/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1375 - val_loss: 2.7529\n",
      "Epoch 8/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1316 - val_loss: 2.3203\n",
      "Epoch 9/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5430 - val_loss: 1.9608\n",
      "Epoch 10/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3895 - val_loss: 1.6687\n",
      "Epoch 11/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1824 - val_loss: 1.4262\n",
      "Epoch 12/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9973 - val_loss: 1.2318\n",
      "Epoch 13/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8846 - val_loss: 1.0709\n",
      "Epoch 14/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7023 - val_loss: 0.9315\n",
      "Epoch 15/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6957 - val_loss: 0.8149\n",
      "Epoch 16/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4656 - val_loss: 0.7118\n",
      "Epoch 17/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4433 - val_loss: 0.6204\n",
      "Epoch 18/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3659 - val_loss: 0.5407\n",
      "Epoch 19/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4347 - val_loss: 0.4719\n",
      "Epoch 20/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2690 - val_loss: 0.4244\n",
      "Epoch 21/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2521 - val_loss: 0.3813\n",
      "Epoch 22/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2486 - val_loss: 0.3466\n",
      "Epoch 23/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2017 - val_loss: 0.3170\n",
      "Epoch 24/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2044 - val_loss: 0.2916\n",
      "Epoch 25/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2041 - val_loss: 0.2715\n",
      "Epoch 26/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2149 - val_loss: 0.2558\n",
      "Epoch 27/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1777 - val_loss: 0.2389\n",
      "Epoch 28/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1583 - val_loss: 0.2271\n",
      "Epoch 29/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1906 - val_loss: 0.2163\n",
      "Epoch 30/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1415 - val_loss: 0.2058\n",
      "Epoch 31/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1589 - val_loss: 0.1982\n",
      "Epoch 32/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1511 - val_loss: 0.1923\n",
      "Epoch 33/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1124 - val_loss: 0.1853\n",
      "Epoch 34/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1233 - val_loss: 0.1780\n",
      "Epoch 35/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1374 - val_loss: 0.1757\n",
      "Epoch 36/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1225 - val_loss: 0.1710\n",
      "Epoch 37/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1182 - val_loss: 0.1678\n",
      "Epoch 38/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1184 - val_loss: 0.1581\n",
      "Epoch 39/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0965 - val_loss: 0.1543\n",
      "Epoch 40/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1203 - val_loss: 0.1498\n",
      "Epoch 41/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1150 - val_loss: 0.1473\n",
      "Epoch 42/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1002 - val_loss: 0.1426\n",
      "Epoch 43/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1179 - val_loss: 0.1363\n",
      "Epoch 44/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1085 - val_loss: 0.1340\n",
      "Epoch 45/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1341 - val_loss: 0.1345\n",
      "Epoch 46/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1003 - val_loss: 0.1284\n",
      "Epoch 47/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0982 - val_loss: 0.1280\n",
      "Epoch 48/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0975 - val_loss: 0.1237\n",
      "Epoch 49/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0855 - val_loss: 0.1208\n",
      "Epoch 50/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0764 - val_loss: 0.1187\n",
      "Epoch 51/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0936 - val_loss: 0.1157\n",
      "Epoch 52/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.1128\n",
      "Epoch 53/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.1110\n",
      "Epoch 54/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0817 - val_loss: 0.1101\n",
      "Epoch 55/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0766 - val_loss: 0.1096\n",
      "Epoch 56/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.1054\n",
      "Epoch 57/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.1036\n",
      "Epoch 58/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.1030\n",
      "Epoch 59/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0643 - val_loss: 0.1016\n",
      "Epoch 60/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0693 - val_loss: 0.0980\n",
      "Epoch 61/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0787 - val_loss: 0.0973\n",
      "Epoch 62/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0679 - val_loss: 0.0957\n",
      "Epoch 63/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0549 - val_loss: 0.0941\n",
      "Epoch 64/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.0934\n",
      "Epoch 65/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0673 - val_loss: 0.0913\n",
      "Epoch 66/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0681 - val_loss: 0.0915\n",
      "Epoch 67/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0697 - val_loss: 0.0890\n",
      "Epoch 68/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0555 - val_loss: 0.0868\n",
      "Epoch 69/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0662 - val_loss: 0.0858\n",
      "Epoch 70/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0720 - val_loss: 0.0876\n",
      "Epoch 71/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0850\n",
      "Epoch 72/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0586 - val_loss: 0.0824\n",
      "Epoch 73/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0539 - val_loss: 0.0809\n",
      "Epoch 74/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0440 - val_loss: 0.0802\n",
      "Epoch 75/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0542 - val_loss: 0.0803\n",
      "Epoch 76/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0494 - val_loss: 0.0786\n",
      "Epoch 77/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0462 - val_loss: 0.0773\n",
      "Epoch 78/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0468 - val_loss: 0.0759\n",
      "Epoch 79/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0624 - val_loss: 0.0745\n",
      "Epoch 80/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0552 - val_loss: 0.0738\n",
      "Epoch 81/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0598 - val_loss: 0.0738\n",
      "Epoch 82/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0449 - val_loss: 0.0715\n",
      "Epoch 83/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0473 - val_loss: 0.0704\n",
      "Epoch 84/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0384 - val_loss: 0.0697\n",
      "Epoch 85/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0425 - val_loss: 0.0687\n",
      "Epoch 86/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0451 - val_loss: 0.0682\n",
      "Epoch 87/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0684\n",
      "Epoch 88/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0515 - val_loss: 0.0664\n",
      "Epoch 89/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0395 - val_loss: 0.0650\n",
      "Epoch 90/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0467 - val_loss: 0.0645\n",
      "Epoch 91/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0440 - val_loss: 0.0639\n",
      "Epoch 92/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0414 - val_loss: 0.0625\n",
      "Epoch 93/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0634\n",
      "Epoch 94/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0427 - val_loss: 0.0617\n",
      "Epoch 95/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0392 - val_loss: 0.0602\n",
      "Epoch 96/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0596\n",
      "Epoch 97/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0490 - val_loss: 0.0593\n",
      "Epoch 98/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0451 - val_loss: 0.0587\n",
      "Epoch 99/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.0576\n",
      "Epoch 100/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0465 - val_loss: 0.0572\n",
      "Epoch 101/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0571\n",
      "Epoch 102/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0448 - val_loss: 0.0559\n",
      "Epoch 103/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0345 - val_loss: 0.0550\n",
      "Epoch 104/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0337 - val_loss: 0.0549\n",
      "Epoch 105/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0466 - val_loss: 0.0546\n",
      "Epoch 106/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - val_loss: 0.0536\n",
      "Epoch 107/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0535\n",
      "Epoch 108/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0474 - val_loss: 0.0532\n",
      "Epoch 109/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0336 - val_loss: 0.0520\n",
      "Epoch 110/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0518\n",
      "Epoch 111/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.0509\n",
      "Epoch 112/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0505\n",
      "Epoch 113/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0350 - val_loss: 0.0499\n",
      "Epoch 114/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0479 - val_loss: 0.0498\n",
      "Epoch 115/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0347 - val_loss: 0.0493\n",
      "Epoch 116/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0395 - val_loss: 0.0487\n",
      "Epoch 117/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0478\n",
      "Epoch 118/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0288 - val_loss: 0.0473\n",
      "Epoch 119/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0394 - val_loss: 0.0475\n",
      "Epoch 120/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0301 - val_loss: 0.0466\n",
      "Epoch 121/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0463\n",
      "Epoch 122/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 0.0457\n",
      "Epoch 123/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0286 - val_loss: 0.0452\n",
      "Epoch 124/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0458\n",
      "Epoch 125/125\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0385 - val_loss: 0.0461\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0401\n",
      "Pérdida en el conjunto de prueba: 0.04611486941576004\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo LSTM con una sola capa\n",
    "model = Sequential()\n",
    "model.add(LSTM(12, input_shape=(X_train.shape[1], 1)))  # 50 neuronas en la capa LSTM\n",
    "model.add(Dense(1))  # Una salida\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train, epochs=125, batch_size=32, validation_data=(X_test, y_test))\n",
    "# Evaluar el modelo\n",
    "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en validación')\n",
    "plt.title('Historia del entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.0137 - val_loss: 7.8899\n",
      "Epoch 2/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6410 - val_loss: 7.2718\n",
      "Epoch 3/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7946 - val_loss: 6.3467\n",
      "Epoch 4/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.3252 - val_loss: 5.0721\n",
      "Epoch 5/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.5725 - val_loss: 3.7520\n",
      "Epoch 6/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5632 - val_loss: 2.8400\n",
      "Epoch 7/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0678 - val_loss: 2.2987\n",
      "Epoch 8/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5000 - val_loss: 1.9356\n",
      "Epoch 9/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4311 - val_loss: 1.6177\n",
      "Epoch 10/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1364 - val_loss: 1.3794\n",
      "Epoch 11/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8718 - val_loss: 1.2151\n",
      "Epoch 12/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7837 - val_loss: 1.0415\n",
      "Epoch 13/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6535 - val_loss: 0.8803\n",
      "Epoch 14/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6317 - val_loss: 0.7687\n",
      "Epoch 15/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5558 - val_loss: 0.6761\n",
      "Epoch 16/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4398 - val_loss: 0.6409\n",
      "Epoch 17/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4725 - val_loss: 0.5774\n",
      "Epoch 18/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5957 - val_loss: 0.5864\n",
      "Epoch 19/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3864 - val_loss: 0.5263\n",
      "Epoch 20/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4154 - val_loss: 0.5190\n",
      "Epoch 21/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3849 - val_loss: 0.5149\n",
      "Epoch 22/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4679 - val_loss: 0.4724\n",
      "Epoch 23/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2911 - val_loss: 0.4715\n",
      "Epoch 24/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3329 - val_loss: 0.4364\n",
      "Epoch 25/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3460 - val_loss: 0.4220\n",
      "Epoch 26/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3336 - val_loss: 0.3993\n",
      "Epoch 27/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3148 - val_loss: 0.3882\n",
      "Epoch 28/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2679 - val_loss: 0.3700\n",
      "Epoch 29/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3481 - val_loss: 0.3573\n",
      "Epoch 30/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3118 - val_loss: 0.3454\n",
      "Epoch 31/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2532 - val_loss: 0.3293\n",
      "Epoch 32/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2440 - val_loss: 0.3137\n",
      "Epoch 33/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2622 - val_loss: 0.3060\n",
      "Epoch 34/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2291 - val_loss: 0.2903\n",
      "Epoch 35/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2597 - val_loss: 0.2892\n",
      "Epoch 36/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2262 - val_loss: 0.2762\n",
      "Epoch 37/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2056 - val_loss: 0.2742\n",
      "Epoch 38/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1935 - val_loss: 0.2536\n",
      "Epoch 39/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1877 - val_loss: 0.2466\n",
      "Epoch 40/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2448 - val_loss: 0.2400\n",
      "Epoch 41/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2314 - val_loss: 0.2322\n",
      "Epoch 42/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2136 - val_loss: 0.2268\n",
      "Epoch 43/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2359 - val_loss: 0.2188\n",
      "Epoch 44/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1763 - val_loss: 0.2105\n",
      "Epoch 45/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2279 - val_loss: 0.2384\n",
      "Epoch 46/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2130 - val_loss: 0.2087\n",
      "Epoch 47/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2173 - val_loss: 0.2196\n",
      "Epoch 48/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1594 - val_loss: 0.1937\n",
      "Epoch 49/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1582 - val_loss: 0.1954\n",
      "Epoch 50/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2149 - val_loss: 0.1811\n",
      "Epoch 51/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1363 - val_loss: 0.1756\n",
      "Epoch 52/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1549 - val_loss: 0.1808\n",
      "Epoch 53/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1468 - val_loss: 0.1742\n",
      "Epoch 54/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1621 - val_loss: 0.1785\n",
      "Epoch 55/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1442 - val_loss: 0.1581\n",
      "Epoch 56/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1581 - val_loss: 0.1680\n",
      "Epoch 57/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1788 - val_loss: 0.1569\n",
      "Epoch 58/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1397 - val_loss: 0.1646\n",
      "Epoch 59/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1474 - val_loss: 0.1524\n",
      "Epoch 60/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1689 - val_loss: 0.1662\n",
      "Epoch 61/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1734 - val_loss: 0.1492\n",
      "Epoch 62/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1412 - val_loss: 0.1546\n",
      "Epoch 63/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1300 - val_loss: 0.1446\n",
      "Epoch 64/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1346 - val_loss: 0.1526\n",
      "Epoch 65/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1343 - val_loss: 0.1343\n",
      "Epoch 66/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1131 - val_loss: 0.1350\n",
      "Epoch 67/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1401 - val_loss: 0.1329\n",
      "Epoch 68/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1329 - val_loss: 0.1298\n",
      "Epoch 69/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1176 - val_loss: 0.1271\n",
      "Epoch 70/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1041 - val_loss: 0.1325\n",
      "Epoch 71/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1120 - val_loss: 0.1329\n",
      "Epoch 72/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1172 - val_loss: 0.1386\n",
      "Epoch 73/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1252 - val_loss: 0.1227\n",
      "Epoch 74/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0886 - val_loss: 0.1213\n",
      "Epoch 75/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0939 - val_loss: 0.1190\n",
      "Epoch 76/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1019 - val_loss: 0.1172\n",
      "Epoch 77/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0904 - val_loss: 0.1157\n",
      "Epoch 78/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0772 - val_loss: 0.1176\n",
      "Epoch 79/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0939 - val_loss: 0.1184\n",
      "Epoch 80/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0934 - val_loss: 0.1086\n",
      "Epoch 81/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0794 - val_loss: 0.1129\n",
      "Epoch 82/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0825 - val_loss: 0.1159\n",
      "Epoch 83/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0896 - val_loss: 0.1195\n",
      "Epoch 84/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0936 - val_loss: 0.1102\n",
      "Epoch 85/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1000 - val_loss: 0.1095\n",
      "Epoch 86/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0715 - val_loss: 0.1015\n",
      "Epoch 87/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0745 - val_loss: 0.1025\n",
      "Epoch 88/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0792 - val_loss: 0.1016\n",
      "Epoch 89/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0600 - val_loss: 0.0960\n",
      "Epoch 90/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0762 - val_loss: 0.0976\n",
      "Epoch 91/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0629 - val_loss: 0.0969\n",
      "Epoch 92/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0665 - val_loss: 0.0969\n",
      "Epoch 93/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0672 - val_loss: 0.0948\n",
      "Epoch 94/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0670 - val_loss: 0.0889\n",
      "Epoch 95/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0562 - val_loss: 0.0901\n",
      "Epoch 96/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0646 - val_loss: 0.0909\n",
      "Epoch 97/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0647 - val_loss: 0.0838\n",
      "Epoch 98/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0597 - val_loss: 0.0833\n",
      "Epoch 99/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0619 - val_loss: 0.0848\n",
      "Epoch 100/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0517 - val_loss: 0.0801\n",
      "Epoch 101/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0599 - val_loss: 0.0816\n",
      "Epoch 102/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0497 - val_loss: 0.0789\n",
      "Epoch 103/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0651 - val_loss: 0.0757\n",
      "Epoch 104/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0624 - val_loss: 0.0752\n",
      "Epoch 105/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0471 - val_loss: 0.0761\n",
      "Epoch 106/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0567 - val_loss: 0.0767\n",
      "Epoch 107/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0542 - val_loss: 0.0713\n",
      "Epoch 108/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0491 - val_loss: 0.0689\n",
      "Epoch 109/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0455 - val_loss: 0.0671\n",
      "Epoch 110/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0482 - val_loss: 0.0688\n",
      "Epoch 111/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0591 - val_loss: 0.0653\n",
      "Epoch 112/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0450 - val_loss: 0.0635\n",
      "Epoch 113/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0479 - val_loss: 0.0661\n",
      "Epoch 114/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0504 - val_loss: 0.0663\n",
      "Epoch 115/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0493 - val_loss: 0.0655\n",
      "Epoch 116/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0440 - val_loss: 0.0611\n",
      "Epoch 117/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0421 - val_loss: 0.0592\n",
      "Epoch 118/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0433 - val_loss: 0.0576\n",
      "Epoch 119/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0410 - val_loss: 0.0576\n",
      "Epoch 120/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0497 - val_loss: 0.0570\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0489 \n",
      "Pérdida en el conjunto de prueba: 0.05700770393013954\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo LSTM con múltiples capas\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa LSTM con return_sequences=True\n",
    "model.add(LSTM(12, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Segunda capa LSTM con return_sequences=True\n",
    "model.add(LSTM(12, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "model.add(LSTM(12, return_sequences=False))  \n",
    "# Última capa sin return_sequences\n",
    "\n",
    "# Capa de salida\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train, epochs=125, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida en el conjunto de prueba: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no tiene sentido que utilicemos el ID para un algoritmo de predicción ya que al ser random no tiene nada que ver con las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4** Elimina los outliers y vuelve a representar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando los datos vemos que hay muchos valores NAN,los vamos a eliminar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una primera version del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10540/1710813634.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"clase\"] = encoder.fit_transform(data['clase'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Codificar las clases: 'benigno' -> 0, 'maligno' -> 1\n",
    "data[\"clase\"] = encoder.fit_transform(data['clase'])\n",
    "y = data[\"clase\"]  # Variable objetivo (la columna 'classe')\n",
    "X = data.drop(columns=[\"clase\"])  # Características (todo menos 'classe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Matriz de confusión:\n",
      "[[84  3]\n",
      " [ 3 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        87\n",
      "           1       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "1\n",
      "Matriz de confusión:\n",
      "[[90  0]\n",
      " [ 2 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        90\n",
      "           1       1.00      0.96      0.98        47\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "2\n",
      "Matriz de confusión:\n",
      "[[79  4]\n",
      " [ 2 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        83\n",
      "           1       0.93      0.96      0.95        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "3\n",
      "Matriz de confusión:\n",
      "[[75  3]\n",
      " [ 3 56]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        78\n",
      "           1       0.95      0.95      0.95        59\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "4\n",
      "Matriz de confusión:\n",
      "[[86  4]\n",
      " [ 0 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        90\n",
      "           1       0.92      1.00      0.96        47\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.96      0.98      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "5\n",
      "Matriz de confusión:\n",
      "[[90  0]\n",
      " [ 1 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        90\n",
      "           1       1.00      0.98      0.99        47\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "6\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 2 54]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        81\n",
      "           1       0.98      0.96      0.97        56\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "7\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        89\n",
      "           1       0.94      0.96      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "8\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        84\n",
      "           1       1.00      0.96      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "9\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        84\n",
      "           1       1.00      0.96      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "10\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        89\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "11\n",
      "Matriz de confusión:\n",
      "[[85  1]\n",
      " [ 1 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        86\n",
      "           1       0.98      0.98      0.98        51\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "12\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 5 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        81\n",
      "           1       0.96      0.91      0.94        56\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "13\n",
      "Matriz de confusión:\n",
      "[[87  4]\n",
      " [ 6 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        91\n",
      "           1       0.91      0.87      0.89        46\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.92      0.91      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "14\n",
      "Matriz de confusión:\n",
      "[[83  1]\n",
      " [ 3 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        84\n",
      "           1       0.98      0.94      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "15\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 4 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        81\n",
      "           1       0.96      0.93      0.95        56\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "16\n",
      "Matriz de confusión:\n",
      "[[90  2]\n",
      " [ 2 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        92\n",
      "           1       0.96      0.96      0.96        45\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "17\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        88\n",
      "           1       0.94      0.96      0.95        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "18\n",
      "Matriz de confusión:\n",
      "[[78  3]\n",
      " [ 2 54]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97        81\n",
      "           1       0.95      0.96      0.96        56\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "19\n",
      "Matriz de confusión:\n",
      "[[92  1]\n",
      " [ 3 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        93\n",
      "           1       0.98      0.93      0.95        44\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "20\n",
      "Matriz de confusión:\n",
      "[[94  5]\n",
      " [ 2 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        99\n",
      "           1       0.88      0.95      0.91        38\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.93      0.95      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "21\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 4 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        84\n",
      "           1       1.00      0.92      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "22\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 1 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        89\n",
      "           1       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "23\n",
      "Matriz de confusión:\n",
      "[[82  1]\n",
      " [ 2 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        83\n",
      "           1       0.98      0.96      0.97        54\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "24\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 4 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        88\n",
      "           1       0.96      0.92      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "25\n",
      "Matriz de confusión:\n",
      "[[93  3]\n",
      " [ 1 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        96\n",
      "           1       0.93      0.98      0.95        41\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.96      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "26\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 0 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        89\n",
      "           1       0.98      1.00      0.99        48\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "27\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        84\n",
      "           1       0.96      0.96      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "28\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [ 6 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        88\n",
      "           1       0.98      0.88      0.92        49\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "29\n",
      "Matriz de confusión:\n",
      "[[93  0]\n",
      " [ 3 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        93\n",
      "           1       1.00      0.93      0.96        44\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "30\n",
      "Matriz de confusión:\n",
      "[[93  3]\n",
      " [ 4 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        96\n",
      "           1       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "31\n",
      "Matriz de confusión:\n",
      "[[90  1]\n",
      " [ 3 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        91\n",
      "           1       0.98      0.93      0.96        46\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "32\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 5 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        87\n",
      "           1       0.98      0.90      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "33\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 2 54]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        81\n",
      "           1       0.98      0.96      0.97        56\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "34\n",
      "Matriz de confusión:\n",
      "[[84  3]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        87\n",
      "           1       0.94      0.92      0.93        50\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "35\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        88\n",
      "           1       0.94      0.96      0.95        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "36\n",
      "Matriz de confusión:\n",
      "[[80  3]\n",
      " [ 3 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        83\n",
      "           1       0.94      0.94      0.94        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "37\n",
      "Matriz de confusión:\n",
      "[[80  2]\n",
      " [ 3 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        82\n",
      "           1       0.96      0.95      0.95        55\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "38\n",
      "Matriz de confusión:\n",
      "[[83  3]\n",
      " [ 3 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        86\n",
      "           1       0.94      0.94      0.94        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "39\n",
      "Matriz de confusión:\n",
      "[[89  0]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        89\n",
      "           1       1.00      0.92      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "40\n",
      "Matriz de confusión:\n",
      "[[87  0]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        87\n",
      "           1       1.00      0.92      0.96        50\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "41\n",
      "Matriz de confusión:\n",
      "[[91  5]\n",
      " [ 1 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97        96\n",
      "           1       0.89      0.98      0.93        41\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.94      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "42\n",
      "Matriz de confusión:\n",
      "[[78  1]\n",
      " [ 5 53]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        79\n",
      "           1       0.98      0.91      0.95        58\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "43\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 4 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        88\n",
      "           1       0.96      0.92      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "44\n",
      "Matriz de confusión:\n",
      "[[83  3]\n",
      " [ 3 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        86\n",
      "           1       0.94      0.94      0.94        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "45\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 3 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        91\n",
      "           1       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "46\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 1 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        84\n",
      "           1       0.96      0.98      0.97        53\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "47\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        88\n",
      "           1       0.98      0.96      0.97        49\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "48\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [ 1 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97        89\n",
      "           1       0.90      0.98      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "49\n",
      "Matriz de confusión:\n",
      "[[81  2]\n",
      " [ 3 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        83\n",
      "           1       0.96      0.94      0.95        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "50\n",
      "Matriz de confusión:\n",
      "[[85  0]\n",
      " [ 2 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        85\n",
      "           1       1.00      0.96      0.98        52\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "51\n",
      "Matriz de confusión:\n",
      "[[83  0]\n",
      " [ 2 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        83\n",
      "           1       1.00      0.96      0.98        54\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "52\n",
      "Matriz de confusión:\n",
      "[[87  3]\n",
      " [ 1 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        90\n",
      "           1       0.94      0.98      0.96        47\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.96      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "53\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 6 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        89\n",
      "           1       0.98      0.88      0.92        48\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "54\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        89\n",
      "           1       0.94      0.94      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "55\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        89\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "56\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        89\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "57\n",
      "Matriz de confusión:\n",
      "[[90  2]\n",
      " [ 2 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        92\n",
      "           1       0.96      0.96      0.96        45\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "58\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 4 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        88\n",
      "           1       0.94      0.92      0.93        49\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "59\n",
      "Matriz de confusión:\n",
      "[[88  2]\n",
      " [ 5 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        90\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "60\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 1 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        87\n",
      "           1       0.96      0.98      0.97        50\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "61\n",
      "Matriz de confusión:\n",
      "[[74  6]\n",
      " [ 6 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        80\n",
      "           1       0.89      0.89      0.89        57\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.91      0.91       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "62\n",
      "Matriz de confusión:\n",
      "[[87  0]\n",
      " [ 1 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        87\n",
      "           1       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "63\n",
      "Matriz de confusión:\n",
      "[[96  1]\n",
      " [ 6 34]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        97\n",
      "           1       0.97      0.85      0.91        40\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.92      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "64\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [ 0 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        89\n",
      "           1       0.91      1.00      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.97      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "65\n",
      "Matriz de confusión:\n",
      "[[80  4]\n",
      " [ 3 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96        84\n",
      "           1       0.93      0.94      0.93        53\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.95      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "66\n",
      "Matriz de confusión:\n",
      "[[94  2]\n",
      " [ 0 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        96\n",
      "           1       0.95      1.00      0.98        41\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.99      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "67\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        89\n",
      "           1       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "68\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 6 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        87\n",
      "           1       0.96      0.88      0.92        50\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "69\n",
      "Matriz de confusión:\n",
      "[[88  4]\n",
      " [ 4 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        92\n",
      "           1       0.91      0.91      0.91        45\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.93      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "70\n",
      "Matriz de confusión:\n",
      "[[84  1]\n",
      " [ 2 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        85\n",
      "           1       0.98      0.96      0.97        52\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "71\n",
      "Matriz de confusión:\n",
      "[[82  1]\n",
      " [ 0 54]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        83\n",
      "           1       0.98      1.00      0.99        54\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "72\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 1 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        88\n",
      "           1       0.96      0.98      0.97        49\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "73\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 1 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        89\n",
      "           1       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "74\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        89\n",
      "           1       0.98      0.96      0.97        48\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "75\n",
      "Matriz de confusión:\n",
      "[[84  3]\n",
      " [ 1 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        87\n",
      "           1       0.94      0.98      0.96        50\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "76\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 2 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        92\n",
      "           1       0.98      0.96      0.97        45\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "77\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 0 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        91\n",
      "           1       0.96      1.00      0.98        46\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.99      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "78\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 1 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        87\n",
      "           1       0.98      0.98      0.98        50\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "79\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        87\n",
      "           1       0.98      0.92      0.95        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "80\n",
      "Matriz de confusión:\n",
      "[[92  0]\n",
      " [ 3 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        92\n",
      "           1       1.00      0.93      0.97        45\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "81\n",
      "Matriz de confusión:\n",
      "[[95  0]\n",
      " [ 2 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        95\n",
      "           1       1.00      0.95      0.98        42\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "82\n",
      "Matriz de confusión:\n",
      "[[73  4]\n",
      " [ 2 58]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        77\n",
      "           1       0.94      0.97      0.95        60\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "83\n",
      "Matriz de confusión:\n",
      "[[89  3]\n",
      " [ 2 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.93      0.96      0.95        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "84\n",
      "Matriz de confusión:\n",
      "[[92  1]\n",
      " [ 2 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        93\n",
      "           1       0.98      0.95      0.97        44\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "85\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 2 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        91\n",
      "           1       0.96      0.96      0.96        46\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "86\n",
      "Matriz de confusión:\n",
      "[[87  3]\n",
      " [ 2 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        90\n",
      "           1       0.94      0.96      0.95        47\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "87\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        88\n",
      "           1       0.96      0.96      0.96        49\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "88\n",
      "Matriz de confusión:\n",
      "[[93  1]\n",
      " [ 2 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        94\n",
      "           1       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "89\n",
      "Matriz de confusión:\n",
      "[[89  3]\n",
      " [ 4 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        92\n",
      "           1       0.93      0.91      0.92        45\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "90\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 0 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        88\n",
      "           1       0.96      1.00      0.98        49\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.99      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "91\n",
      "Matriz de confusión:\n",
      "[[88  2]\n",
      " [ 6 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        90\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "92\n",
      "Matriz de confusión:\n",
      "[[94  1]\n",
      " [ 3 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        95\n",
      "           1       0.97      0.93      0.95        42\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "93\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 2 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        91\n",
      "           1       0.96      0.96      0.96        46\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "94\n",
      "Matriz de confusión:\n",
      "[[88  0]\n",
      " [ 1 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        88\n",
      "           1       1.00      0.98      0.99        49\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "95\n",
      "Matriz de confusión:\n",
      "[[84  2]\n",
      " [ 1 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        86\n",
      "           1       0.96      0.98      0.97        51\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "96\n",
      "Matriz de confusión:\n",
      "[[85  0]\n",
      " [ 1 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        85\n",
      "           1       1.00      0.98      0.99        52\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "97\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 3 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        88\n",
      "           1       0.94      0.94      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "98\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        84\n",
      "           1       0.96      0.96      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "99\n",
      "Matriz de confusión:\n",
      "[[92  2]\n",
      " [ 5 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        94\n",
      "           1       0.95      0.88      0.92        43\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "Mean squared error (Train): 0.02895604395604395 \n",
      "Absolute squared error (Train): 0.02895604395604395 \n",
      "R2 score (Train): 0.8723152951546528 \n",
      "Mean squared error (Test): 0.03255474452554745 \n",
      "Absolute squared error (Test): 0.03255474452554745 \n",
      "R2 score (Test): 0.8573802854247874 \n",
      "Característica: V1, Coeficiente: 0.4670\n",
      "Característica: V2, Coeficiente: 0.0390\n",
      "Característica: V3, Coeficiente: 0.2998\n",
      "Característica: V4, Coeficiente: 0.3119\n",
      "Característica: V5, Coeficiente: 0.1511\n",
      "Característica: V6, Coeficiente: 0.3334\n",
      "Característica: V7, Coeficiente: 0.6116\n",
      "Característica: V8, Coeficiente: 0.1955\n",
      "Característica: V9, Coeficiente: 0.3271\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print(X)\n",
    "#print(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "n=100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "mse_results =[]\n",
    "mae_results =[]\n",
    "mse_train = []\n",
    "mae_train = []\n",
    "r2_results =[]\n",
    "r2_train = []\n",
    "error_test =[]\n",
    "error_train = []\n",
    "for i in range(n):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=i)\n",
    "\n",
    "\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Train Predict\n",
    "\n",
    "    y_predict = model.predict(X_train)\n",
    "    mse_train.append(mean_squared_error(y_train,  y_predict))\n",
    "    mae_train.append(mean_absolute_error(y_train, y_predict))\n",
    "    r2_train.append(r2_score(y_train , y_predict))\n",
    "    error_train.append(y_train  - (y_predict))\n",
    "    print(i)\n",
    "    # Test Predict\n",
    "    y_predict = model.predict(X_test)\n",
    "    mse_results.append(mean_squared_error(y_test,  y_predict))\n",
    "    mae_results.append(mean_absolute_error(y_test, y_predict))\n",
    "    r2_results.append(r2_score(y_test , y_predict))\n",
    "    error_test.append(y_test  - (y_predict))\n",
    "    #mostramos amtriz de confusionpara cada modelo\n",
    "    conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(conf_matrix)\n",
    "    #mostramos reporte de calsificacion\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Figure\n",
    "\n",
    "\n",
    "# Predict on training data\n",
    "print(f\"Mean squared error (Train): {np.mean(mse_train)} \")\n",
    "print(f\"Absolute squared error (Train): {np.mean(mae_train)} \")\n",
    "print(f\"R2 score (Train): {np.mean(r2_train)} \")\n",
    "\n",
    "# Predict on test data\n",
    "print(f\"Mean squared error (Test): {np.mean(mse_results)} \")\n",
    "print(f\"Absolute squared error (Test): {np.mean(mae_results)} \")\n",
    "print(f\"R2 score (Test): {np.mean(r2_results)} \")\n",
    "\n",
    "# Obtener los coeficientes del modelo\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Mostrar los coeficientes junto con los nombres de las características\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Característica: {feature}, Coeficiente: {coef:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo los coeficientes del modelo para ver como influyen las diferentes caracteísticas en la predicción del ultimo modelo creado por ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exlorando este primer modelo vemos que los mayores coeficientes ordenados de mayor a menor son:V7,V1 y V6(muy igualado con V4 Y V9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la información que has conseguido del análisis realizado, crea un primera versión de un regresor logístico que utilice una única característica. ¿Qué característica vas a utilizar? ¿Por qué has elegido esa característica?\n",
    "\n",
    "Voy a crear un modelo con la única caractrística V7 ya que es la que mayor coeficiente tiene y por tanto es la que más interviene en la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[82  5]\n",
      " [ 7 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        87\n",
      "           1       0.90      0.86      0.88        50\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 9 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        90\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[78  5]\n",
      " [11 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        83\n",
      "           1       0.90      0.80      0.84        54\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[73  5]\n",
      " [ 8 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        78\n",
      "           1       0.91      0.86      0.89        59\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  4]\n",
      " [ 4 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        90\n",
      "           1       0.91      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  4]\n",
      " [ 9 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        90\n",
      "           1       0.90      0.81      0.85        47\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.88      0.89       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 9 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.93        81\n",
      "           1       0.96      0.84      0.90        56\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.93      0.91      0.92       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [11 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        89\n",
      "           1       0.95      0.77      0.85        48\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.87      0.89       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  3]\n",
      " [13 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        84\n",
      "           1       0.93      0.75      0.83        53\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.90      0.86      0.87       137\n",
      "weighted avg       0.89      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [10 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        84\n",
      "           1       0.96      0.81      0.88        53\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.89      0.90       137\n",
      "weighted avg       0.92      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 8 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        89\n",
      "           1       0.93      0.83      0.88        48\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  4]\n",
      " [ 8 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        86\n",
      "           1       0.91      0.84      0.88        51\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 9 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.93        81\n",
      "           1       0.96      0.84      0.90        56\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.93      0.91      0.92       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[87  4]\n",
      " [10 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        91\n",
      "           1       0.90      0.78      0.84        46\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.90      0.87      0.88       137\n",
      "weighted avg       0.90      0.90      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [12 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92        84\n",
      "           1       0.95      0.77      0.85        53\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.91      0.87      0.89       137\n",
      "weighted avg       0.90      0.90      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[78  3]\n",
      " [12 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        81\n",
      "           1       0.94      0.79      0.85        56\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.90      0.87      0.88       137\n",
      "weighted avg       0.90      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  4]\n",
      " [ 7 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        92\n",
      "           1       0.90      0.84      0.87        45\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  7]\n",
      " [ 9 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91        88\n",
      "           1       0.85      0.82      0.83        49\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.88      0.87      0.87       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 7 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        81\n",
      "           1       0.96      0.88      0.92        56\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.93      0.93       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[93  0]\n",
      " [19 25]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        93\n",
      "           1       1.00      0.57      0.72        44\n",
      "\n",
      "    accuracy                           0.86       137\n",
      "   macro avg       0.92      0.78      0.82       137\n",
      "weighted avg       0.88      0.86      0.85       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[97  2]\n",
      " [ 5 33]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        99\n",
      "           1       0.94      0.87      0.90        38\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.92      0.93       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 8 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        84\n",
      "           1       0.96      0.85      0.90        53\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.91      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 7 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        89\n",
      "           1       0.98      0.85      0.91        48\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.92      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  2]\n",
      " [10 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        83\n",
      "           1       0.96      0.81      0.88        54\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [13 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        88\n",
      "           1       0.90      0.73      0.81        49\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.88      0.84      0.86       137\n",
      "weighted avg       0.88      0.88      0.87       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[91  5]\n",
      " [ 8 33]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93        96\n",
      "           1       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.89      0.88      0.88       137\n",
      "weighted avg       0.90      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  7]\n",
      " [ 8 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92        89\n",
      "           1       0.85      0.83      0.84        48\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.88      0.88      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  3]\n",
      " [ 9 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        84\n",
      "           1       0.94      0.83      0.88        53\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  0]\n",
      " [23 26]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        88\n",
      "           1       1.00      0.53      0.69        49\n",
      "\n",
      "    accuracy                           0.83       137\n",
      "   macro avg       0.90      0.77      0.79       137\n",
      "weighted avg       0.87      0.83      0.82       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[87  6]\n",
      " [ 6 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        93\n",
      "           1       0.86      0.86      0.86        44\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.90      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[91  5]\n",
      " [11 30]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        96\n",
      "           1       0.86      0.73      0.79        41\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.87      0.84      0.85       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  3]\n",
      " [ 8 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        91\n",
      "           1       0.93      0.83      0.87        46\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [10 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        87\n",
      "           1       0.95      0.80      0.87        50\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.89      0.90       137\n",
      "weighted avg       0.92      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 7 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        81\n",
      "           1       0.98      0.88      0.92        56\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 9 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        87\n",
      "           1       0.98      0.82      0.89        50\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [ 8 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        88\n",
      "           1       0.91      0.84      0.87        49\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[75  8]\n",
      " [11 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89        83\n",
      "           1       0.84      0.80      0.82        54\n",
      "\n",
      "    accuracy                           0.86       137\n",
      "   macro avg       0.86      0.85      0.85       137\n",
      "weighted avg       0.86      0.86      0.86       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[77  5]\n",
      " [18 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87        82\n",
      "           1       0.88      0.67      0.76        55\n",
      "\n",
      "    accuracy                           0.83       137\n",
      "   macro avg       0.85      0.81      0.82       137\n",
      "weighted avg       0.84      0.83      0.83       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[80  6]\n",
      " [ 8 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        86\n",
      "           1       0.88      0.84      0.86        51\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.89      0.89      0.89       137\n",
      "weighted avg       0.90      0.90      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 9 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.93        89\n",
      "           1       0.93      0.81      0.87        48\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.89      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [17 33]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.91        87\n",
      "           1       0.97      0.66      0.79        50\n",
      "\n",
      "    accuracy                           0.87       137\n",
      "   macro avg       0.90      0.82      0.85       137\n",
      "weighted avg       0.88      0.87      0.86       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  8]\n",
      " [ 3 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        96\n",
      "           1       0.83      0.93      0.87        41\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.90      0.92      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[74  5]\n",
      " [13 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89        79\n",
      "           1       0.90      0.78      0.83        58\n",
      "\n",
      "    accuracy                           0.87       137\n",
      "   macro avg       0.88      0.86      0.86       137\n",
      "weighted avg       0.87      0.87      0.87       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [11 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92        88\n",
      "           1       0.90      0.78      0.84        49\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[78  8]\n",
      " [ 7 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        86\n",
      "           1       0.85      0.86      0.85        51\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.88      0.88      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  3]\n",
      " [ 6 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        91\n",
      "           1       0.93      0.87      0.90        46\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.93       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  3]\n",
      " [ 7 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        84\n",
      "           1       0.94      0.87      0.90        53\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 8 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        88\n",
      "           1       0.93      0.84      0.88        49\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  7]\n",
      " [ 6 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93        89\n",
      "           1       0.86      0.88      0.87        48\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.89      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[78  5]\n",
      " [10 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        83\n",
      "           1       0.90      0.81      0.85        54\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.88      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[83  2]\n",
      " [10 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        85\n",
      "           1       0.95      0.81      0.88        52\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.89      0.90       137\n",
      "weighted avg       0.92      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[80  3]\n",
      " [ 6 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        83\n",
      "           1       0.94      0.89      0.91        54\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.93      0.93       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  4]\n",
      " [ 7 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        90\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [10 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        89\n",
      "           1       0.93      0.79      0.85        48\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.88      0.89       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [10 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        89\n",
      "           1       0.93      0.79      0.85        48\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.88      0.89       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [12 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        89\n",
      "           1       0.88      0.75      0.81        48\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.88      0.85      0.86       137\n",
      "weighted avg       0.88      0.88      0.87       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [10 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        89\n",
      "           1       0.88      0.79      0.84        48\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  4]\n",
      " [ 7 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        92\n",
      "           1       0.90      0.84      0.87        45\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[83  5]\n",
      " [11 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        88\n",
      "           1       0.88      0.78      0.83        49\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.88      0.86      0.87       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  2]\n",
      " [ 8 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        90\n",
      "           1       0.95      0.83      0.89        47\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 9 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        87\n",
      "           1       0.98      0.82      0.89        50\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[77  3]\n",
      " [14 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        80\n",
      "           1       0.93      0.75      0.83        57\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.89      0.86      0.87       137\n",
      "weighted avg       0.88      0.88      0.87       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[83  4]\n",
      " [ 6 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        87\n",
      "           1       0.92      0.88      0.90        50\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.92      0.92      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[96  1]\n",
      " [12 28]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        97\n",
      "           1       0.97      0.70      0.81        40\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.93      0.84      0.87       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        89\n",
      "           1       0.94      0.94      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 6 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        84\n",
      "           1       0.96      0.89      0.92        53\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[94  2]\n",
      " [ 7 34]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        96\n",
      "           1       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[89  0]\n",
      " [ 9 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        89\n",
      "           1       1.00      0.81      0.90        48\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.95      0.91      0.92       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [13 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        87\n",
      "           1       0.97      0.74      0.84        50\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.92      0.86      0.88       137\n",
      "weighted avg       0.91      0.90      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[90  2]\n",
      " [11 34]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        92\n",
      "           1       0.94      0.76      0.84        45\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.87      0.89       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  1]\n",
      " [ 6 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        85\n",
      "           1       0.98      0.88      0.93        52\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[79  4]\n",
      " [ 7 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93        83\n",
      "           1       0.92      0.87      0.90        54\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.91      0.92       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[83  5]\n",
      " [10 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        88\n",
      "           1       0.89      0.80      0.84        49\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 6 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        89\n",
      "           1       0.95      0.88      0.91        48\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [11 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        89\n",
      "           1       0.88      0.77      0.82        48\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.88      0.86      0.87       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 9 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        87\n",
      "           1       0.95      0.82      0.88        50\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.93      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  4]\n",
      " [ 7 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        92\n",
      "           1       0.90      0.84      0.87        45\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 7 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        91\n",
      "           1       0.95      0.85      0.90        46\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.91      0.92       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 8 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        87\n",
      "           1       0.98      0.84      0.90        50\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.95      0.91      0.93       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[83  4]\n",
      " [ 9 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93        87\n",
      "           1       0.91      0.82      0.86        50\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.91      0.89      0.90       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[90  2]\n",
      " [10 35]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        92\n",
      "           1       0.95      0.78      0.85        45\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.92      0.88      0.90       137\n",
      "weighted avg       0.92      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[93  2]\n",
      " [ 6 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        95\n",
      "           1       0.95      0.86      0.90        42\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.92      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[72  5]\n",
      " [10 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        77\n",
      "           1       0.91      0.83      0.87        60\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.88      0.89       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  4]\n",
      " [ 7 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        92\n",
      "           1       0.90      0.84      0.87        45\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.90      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[88  5]\n",
      " [ 9 35]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        93\n",
      "           1       0.88      0.80      0.83        44\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.90      0.90      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  7]\n",
      " [ 9 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91        91\n",
      "           1       0.84      0.80      0.82        46\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.87      0.86      0.87       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[83  7]\n",
      " [ 9 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91        90\n",
      "           1       0.84      0.81      0.83        47\n",
      "\n",
      "    accuracy                           0.88       137\n",
      "   macro avg       0.87      0.87      0.87       137\n",
      "weighted avg       0.88      0.88      0.88       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  6]\n",
      " [ 7 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        88\n",
      "           1       0.88      0.86      0.87        49\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.90      0.89      0.90       137\n",
      "weighted avg       0.90      0.91      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[90  4]\n",
      " [11 32]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        94\n",
      "           1       0.89      0.74      0.81        43\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.85      0.87       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[85  7]\n",
      " [ 6 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93        92\n",
      "           1       0.85      0.87      0.86        45\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.89      0.90      0.89       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[80  8]\n",
      " [ 7 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        88\n",
      "           1       0.84      0.86      0.85        49\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.88      0.88      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [10 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        90\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.94      0.89      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[92  3]\n",
      " [ 8 34]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        95\n",
      "           1       0.92      0.81      0.86        42\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.89      0.90       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[86  5]\n",
      " [ 9 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.92        91\n",
      "           1       0.88      0.80      0.84        46\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.90      0.90      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [10 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        88\n",
      "           1       0.97      0.80      0.88        49\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.94      0.89      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  5]\n",
      " [ 9 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        86\n",
      "           1       0.89      0.82      0.86        51\n",
      "\n",
      "    accuracy                           0.90       137\n",
      "   macro avg       0.90      0.88      0.89       137\n",
      "weighted avg       0.90      0.90      0.90       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[82  3]\n",
      " [ 8 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94        85\n",
      "           1       0.94      0.85      0.89        52\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.91      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [11 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92        88\n",
      "           1       0.90      0.78      0.84        49\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.89      0.87      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[81  3]\n",
      " [12 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92        84\n",
      "           1       0.93      0.77      0.85        53\n",
      "\n",
      "    accuracy                           0.89       137\n",
      "   macro avg       0.90      0.87      0.88       137\n",
      "weighted avg       0.89      0.89      0.89       137\n",
      "\n",
      "Matriz de confusión:\n",
      "[[89  5]\n",
      " [ 7 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        94\n",
      "           1       0.88      0.84      0.86        43\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.90      0.89      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "Mean squared error (Train): 0.09358974358974358 \n",
      "Absolute squared error (Train): 0.09358974358974358 \n",
      "R2 score (Train): 0.5874081920024179 \n",
      "Mean squared error (Test): 0.09233576642335768 \n",
      "Absolute squared error (Test): 0.09233576642335768 \n",
      "R2 score (Test): 0.5964079244459115 \n",
      "Característica: V7, Coeficiente: 1.5932\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y = data[\"clase\"]  # Variable objetivo (la columna 'classe')\n",
    "#usamos dos corchetes para indicar que X es un Dataframe y no un vector\n",
    "#  unidimensional Serie,ya que sino da error en el metodo fit\n",
    "X = data[[\"V7\"]]  # Característica V7 soolo\n",
    "#print(y)\n",
    "#print(X)\n",
    "\n",
    "n=100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "mse_results =[]\n",
    "mae_results =[]\n",
    "mse_train = []\n",
    "mae_train = []\n",
    "r2_results =[]\n",
    "r2_train = []\n",
    "error_test =[]\n",
    "error_train = []\n",
    "for i in range(n):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=i)\n",
    "\n",
    "\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Train Predict\n",
    "\n",
    "    y_predict = model.predict(X_train)\n",
    "    mse_train.append(mean_squared_error(y_train,  y_predict))\n",
    "    mae_train.append(mean_absolute_error(y_train, y_predict))\n",
    "    r2_train.append(r2_score(y_train , y_predict))\n",
    "    error_train.append(y_train  - (y_predict))\n",
    "    #print(i)\n",
    "    # Test Predict\n",
    "    y_predict = model.predict(X_test)\n",
    "    mse_results.append(mean_squared_error(y_test,  y_predict))\n",
    "    mae_results.append(mean_absolute_error(y_test, y_predict))\n",
    "    r2_results.append(r2_score(y_test , y_predict))\n",
    "    error_test.append(y_test  - (y_predict))\n",
    "    #mostramos amtriz de confusionpara cada modelo\n",
    "    conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(conf_matrix)\n",
    "    #mostramos reporte de calsificacion\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Figure\n",
    "\n",
    "\n",
    "# Predict on training data\n",
    "print(f\"Mean squared error (Train): {np.mean(mse_train)} \")\n",
    "print(f\"Absolute squared error (Train): {np.mean(mae_train)} \")\n",
    "print(f\"R2 score (Train): {np.mean(r2_train)} \")\n",
    "\n",
    "# Predict on test data\n",
    "print(f\"Mean squared error (Test): {np.mean(mse_results)} \")\n",
    "print(f\"Absolute squared error (Test): {np.mean(mae_results)} \")\n",
    "print(f\"R2 score (Test): {np.mean(r2_results)} \")\n",
    "\n",
    "# Obtener los coeficientes del modelo\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Mostrar los coeficientes junto con los nombres de las características\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Característica: {feature}, Coeficiente: {coef:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un R2 score de 0.59,muy inferior al anterior de 0.82(con todas las características)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amplia el número de características a dos. ¿Cuál es la segunda característica que has seleccionado? ¿Por qué la has seleccionado? ¿Han mejorado los resultados? ¿Cuanto han mejorado?\n",
    "\n",
    "La segunda en orden de influencia es V1 por tanto las 2 caracterísitcas que voy a usar son : V1 y V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "694    0\n",
      "695    0\n",
      "696    1\n",
      "697    1\n",
      "698    1\n",
      "Name: clase, Length: 683, dtype: int64\n",
      "     V7  V1\n",
      "0     3   5\n",
      "1     3   5\n",
      "2     3   3\n",
      "3     3   6\n",
      "4     3   4\n",
      "..   ..  ..\n",
      "694   1   3\n",
      "695   1   2\n",
      "696   8   5\n",
      "697  10   4\n",
      "698  10   4\n",
      "\n",
      "[683 rows x 2 columns]\n",
      "0\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        87\n",
      "           1       0.98      0.92      0.95        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "1\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 4 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        90\n",
      "           1       0.98      0.91      0.95        47\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "2\n",
      "Matriz de confusión:\n",
      "[[83  0]\n",
      " [ 5 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        83\n",
      "           1       1.00      0.91      0.95        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "3\n",
      "Matriz de confusión:\n",
      "[[75  3]\n",
      " [ 7 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94        78\n",
      "           1       0.95      0.88      0.91        59\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "4\n",
      "Matriz de confusión:\n",
      "[[87  3]\n",
      " [ 1 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        90\n",
      "           1       0.94      0.98      0.96        47\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.96      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "5\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 6 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        90\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "6\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 1 55]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        81\n",
      "           1       0.98      0.98      0.98        56\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "7\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        89\n",
      "           1       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "8\n",
      "Matriz de confusión:\n",
      "[[83  1]\n",
      " [ 6 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        84\n",
      "           1       0.98      0.89      0.93        53\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "9\n",
      "Matriz de confusión:\n",
      "[[83  1]\n",
      " [ 5 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97        84\n",
      "           1       0.98      0.91      0.94        53\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "10\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        89\n",
      "           1       0.96      0.92      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "11\n",
      "Matriz de confusión:\n",
      "[[84  2]\n",
      " [ 3 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        86\n",
      "           1       0.96      0.94      0.95        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "12\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 5 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        81\n",
      "           1       0.98      0.91      0.94        56\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "13\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 8 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        91\n",
      "           1       0.95      0.83      0.88        46\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "14\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 4 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        84\n",
      "           1       0.96      0.92      0.94        53\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "15\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [10 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        81\n",
      "           1       0.98      0.82      0.89        56\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.93      0.90      0.91       137\n",
      "weighted avg       0.93      0.92      0.92       137\n",
      "\n",
      "16\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 5 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        92\n",
      "           1       0.98      0.89      0.93        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "17\n",
      "Matriz de confusión:\n",
      "[[81  7]\n",
      " [ 6 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93        88\n",
      "           1       0.86      0.88      0.87        49\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.90      0.90      0.90       137\n",
      "weighted avg       0.91      0.91      0.91       137\n",
      "\n",
      "18\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 7 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        81\n",
      "           1       0.96      0.88      0.92        56\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.93      0.93       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "19\n",
      "Matriz de confusión:\n",
      "[[92  1]\n",
      " [ 9 35]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        93\n",
      "           1       0.97      0.80      0.88        44\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.89      0.91       137\n",
      "weighted avg       0.93      0.93      0.92       137\n",
      "\n",
      "20\n",
      "Matriz de confusión:\n",
      "[[97  2]\n",
      " [ 3 35]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        99\n",
      "           1       0.95      0.92      0.93        38\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "21\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 9 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        84\n",
      "           1       1.00      0.83      0.91        53\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.95      0.92      0.93       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "22\n",
      "Matriz de confusión:\n",
      "[[89  0]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        89\n",
      "           1       1.00      0.92      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "23\n",
      "Matriz de confusión:\n",
      "[[83  0]\n",
      " [ 5 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        83\n",
      "           1       1.00      0.91      0.95        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "24\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 5 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        88\n",
      "           1       0.94      0.90      0.92        49\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "25\n",
      "Matriz de confusión:\n",
      "[[94  2]\n",
      " [ 5 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        96\n",
      "           1       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "26\n",
      "Matriz de confusión:\n",
      "[[85  4]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        89\n",
      "           1       0.92      0.92      0.92        48\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "27\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        84\n",
      "           1       0.96      0.96      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "28\n",
      "Matriz de confusión:\n",
      "[[88  0]\n",
      " [11 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        88\n",
      "           1       1.00      0.78      0.87        49\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.94      0.89      0.91       137\n",
      "weighted avg       0.93      0.92      0.92       137\n",
      "\n",
      "29\n",
      "Matriz de confusión:\n",
      "[[90  3]\n",
      " [ 5 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        93\n",
      "           1       0.93      0.89      0.91        44\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "30\n",
      "Matriz de confusión:\n",
      "[[93  3]\n",
      " [ 4 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        96\n",
      "           1       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "31\n",
      "Matriz de confusión:\n",
      "[[88  3]\n",
      " [ 6 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        91\n",
      "           1       0.93      0.87      0.90        46\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.93       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "32\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 5 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        87\n",
      "           1       0.98      0.90      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "33\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [10 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        81\n",
      "           1       0.98      0.82      0.89        56\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.93      0.90      0.91       137\n",
      "weighted avg       0.93      0.92      0.92       137\n",
      "\n",
      "34\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 3 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        87\n",
      "           1       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "35\n",
      "Matriz de confusión:\n",
      "[[82  6]\n",
      " [ 4 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        88\n",
      "           1       0.88      0.92      0.90        49\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.92      0.93      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "36\n",
      "Matriz de confusión:\n",
      "[[78  5]\n",
      " [ 6 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        83\n",
      "           1       0.91      0.89      0.90        54\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.91      0.92       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "37\n",
      "Matriz de confusión:\n",
      "[[79  3]\n",
      " [ 5 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        82\n",
      "           1       0.94      0.91      0.93        55\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "38\n",
      "Matriz de confusión:\n",
      "[[83  3]\n",
      " [ 7 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        86\n",
      "           1       0.94      0.86      0.90        51\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.91      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "39\n",
      "Matriz de confusión:\n",
      "[[89  0]\n",
      " [ 5 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        89\n",
      "           1       1.00      0.90      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "40\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 2 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        87\n",
      "           1       0.98      0.96      0.97        50\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "41\n",
      "Matriz de confusión:\n",
      "[[87  9]\n",
      " [ 1 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95        96\n",
      "           1       0.82      0.98      0.89        41\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.90      0.94      0.92       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "42\n",
      "Matriz de confusión:\n",
      "[[75  4]\n",
      " [ 7 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        79\n",
      "           1       0.93      0.88      0.90        58\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.91      0.92       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "43\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [12 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        88\n",
      "           1       0.97      0.76      0.85        49\n",
      "\n",
      "    accuracy                           0.91       137\n",
      "   macro avg       0.93      0.87      0.89       137\n",
      "weighted avg       0.91      0.91      0.90       137\n",
      "\n",
      "44\n",
      "Matriz de confusión:\n",
      "[[77  9]\n",
      " [ 2 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93        86\n",
      "           1       0.84      0.96      0.90        51\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.91      0.93      0.92       137\n",
      "weighted avg       0.93      0.92      0.92       137\n",
      "\n",
      "45\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 5 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        91\n",
      "           1       0.95      0.89      0.92        46\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "46\n",
      "Matriz de confusión:\n",
      "[[83  1]\n",
      " [ 4 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        84\n",
      "           1       0.98      0.92      0.95        53\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "47\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 5 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        88\n",
      "           1       0.96      0.90      0.93        49\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "48\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        89\n",
      "           1       0.90      0.94      0.92        48\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.93      0.94      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "49\n",
      "Matriz de confusión:\n",
      "[[80  3]\n",
      " [ 5 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        83\n",
      "           1       0.94      0.91      0.92        54\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "50\n",
      "Matriz de confusión:\n",
      "[[83  2]\n",
      " [ 5 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        85\n",
      "           1       0.96      0.90      0.93        52\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "51\n",
      "Matriz de confusión:\n",
      "[[83  0]\n",
      " [ 6 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        83\n",
      "           1       1.00      0.89      0.94        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "52\n",
      "Matriz de confusión:\n",
      "[[87  3]\n",
      " [ 3 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        90\n",
      "           1       0.94      0.94      0.94        47\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "53\n",
      "Matriz de confusión:\n",
      "[[85  4]\n",
      " [ 5 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        89\n",
      "           1       0.91      0.90      0.91        48\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.93      0.93       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "54\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        89\n",
      "           1       0.96      0.92      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "55\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 6 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        89\n",
      "           1       0.93      0.88      0.90        48\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.93       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "56\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 5 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        89\n",
      "           1       0.93      0.90      0.91        48\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "57\n",
      "Matriz de confusión:\n",
      "[[92  0]\n",
      " [10 35]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        92\n",
      "           1       1.00      0.78      0.88        45\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.95      0.89      0.91       137\n",
      "weighted avg       0.93      0.93      0.92       137\n",
      "\n",
      "58\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [ 6 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        88\n",
      "           1       0.91      0.88      0.90        49\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.92      0.92      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "59\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 6 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        90\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "60\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 2 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        87\n",
      "           1       0.98      0.96      0.97        50\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "61\n",
      "Matriz de confusión:\n",
      "[[77  3]\n",
      " [ 7 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        80\n",
      "           1       0.94      0.88      0.91        57\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "62\n",
      "Matriz de confusión:\n",
      "[[87  0]\n",
      " [ 5 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        87\n",
      "           1       1.00      0.90      0.95        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "63\n",
      "Matriz de confusión:\n",
      "[[95  2]\n",
      " [ 5 35]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        97\n",
      "           1       0.95      0.88      0.91        40\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "64\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [ 0 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        89\n",
      "           1       0.91      1.00      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.97      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "65\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 4 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        84\n",
      "           1       0.96      0.92      0.94        53\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "66\n",
      "Matriz de confusión:\n",
      "[[94  2]\n",
      " [ 1 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        96\n",
      "           1       0.95      0.98      0.96        41\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "67\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        89\n",
      "           1       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "68\n",
      "Matriz de confusión:\n",
      "[[87  0]\n",
      " [10 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        87\n",
      "           1       1.00      0.80      0.89        50\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.95      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.92       137\n",
      "\n",
      "69\n",
      "Matriz de confusión:\n",
      "[[90  2]\n",
      " [ 7 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        92\n",
      "           1       0.95      0.84      0.89        45\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.91      0.92       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "70\n",
      "Matriz de confusión:\n",
      "[[85  0]\n",
      " [ 3 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        85\n",
      "           1       1.00      0.94      0.97        52\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "71\n",
      "Matriz de confusión:\n",
      "[[82  1]\n",
      " [ 4 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        83\n",
      "           1       0.98      0.93      0.95        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "72\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 3 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        88\n",
      "           1       0.96      0.94      0.95        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "73\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 0 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        89\n",
      "           1       0.98      1.00      0.99        48\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "74\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        89\n",
      "           1       0.94      0.94      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "75\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        87\n",
      "           1       0.96      0.92      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "76\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 5 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        92\n",
      "           1       0.98      0.89      0.93        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "77\n",
      "Matriz de confusión:\n",
      "[[90  1]\n",
      " [ 4 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        91\n",
      "           1       0.98      0.91      0.94        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "78\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 2 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        87\n",
      "           1       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "79\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 6 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        87\n",
      "           1       0.96      0.88      0.92        50\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "80\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 6 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        92\n",
      "           1       0.97      0.87      0.92        45\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "81\n",
      "Matriz de confusión:\n",
      "[[95  0]\n",
      " [ 4 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        95\n",
      "           1       1.00      0.90      0.95        42\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.95      0.96       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "82\n",
      "Matriz de confusión:\n",
      "[[74  3]\n",
      " [ 4 56]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        77\n",
      "           1       0.95      0.93      0.94        60\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "83\n",
      "Matriz de confusión:\n",
      "[[89  3]\n",
      " [ 4 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        92\n",
      "           1       0.93      0.91      0.92        45\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "84\n",
      "Matriz de confusión:\n",
      "[[90  3]\n",
      " [ 3 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        93\n",
      "           1       0.93      0.93      0.93        44\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "85\n",
      "Matriz de confusión:\n",
      "[[88  3]\n",
      " [ 3 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        91\n",
      "           1       0.93      0.93      0.93        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "86\n",
      "Matriz de confusión:\n",
      "[[86  4]\n",
      " [ 3 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96        90\n",
      "           1       0.92      0.94      0.93        47\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.95      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "87\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 3 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        88\n",
      "           1       0.94      0.94      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "88\n",
      "Matriz de confusión:\n",
      "[[93  1]\n",
      " [ 4 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        94\n",
      "           1       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "89\n",
      "Matriz de confusión:\n",
      "[[86  6]\n",
      " [ 4 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        92\n",
      "           1       0.87      0.91      0.89        45\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.91      0.92      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "90\n",
      "Matriz de confusión:\n",
      "[[83  5]\n",
      " [ 1 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97        88\n",
      "           1       0.91      0.98      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "91\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 6 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        90\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "92\n",
      "Matriz de confusión:\n",
      "[[94  1]\n",
      " [ 4 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        95\n",
      "           1       0.97      0.90      0.94        42\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "93\n",
      "Matriz de confusión:\n",
      "[[90  1]\n",
      " [ 5 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        91\n",
      "           1       0.98      0.89      0.93        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "94\n",
      "Matriz de confusión:\n",
      "[[88  0]\n",
      " [ 3 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        88\n",
      "           1       1.00      0.94      0.97        49\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "95\n",
      "Matriz de confusión:\n",
      "[[84  2]\n",
      " [ 2 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        86\n",
      "           1       0.96      0.96      0.96        51\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "96\n",
      "Matriz de confusión:\n",
      "[[85  0]\n",
      " [ 3 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        85\n",
      "           1       1.00      0.94      0.97        52\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "97\n",
      "Matriz de confusión:\n",
      "[[83  5]\n",
      " [ 6 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94        88\n",
      "           1       0.90      0.88      0.89        49\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.91      0.91      0.91       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "98\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 6 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        84\n",
      "           1       0.96      0.89      0.92        53\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "99\n",
      "Matriz de confusión:\n",
      "[[89  5]\n",
      " [ 4 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        94\n",
      "           1       0.89      0.91      0.90        43\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.92      0.93      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "Mean squared error (Train): 0.0515018315018315 \n",
      "Absolute squared error (Train): 0.0515018315018315 \n",
      "R2 score (Train): 0.7729263397944659 \n",
      "Mean squared error (Test): 0.05014598540145985 \n",
      "Absolute squared error (Test): 0.05014598540145985 \n",
      "R2 score (Test): 0.7806924885792336 \n",
      "Característica: V7, Coeficiente: 1.5120\n",
      "Característica: V1, Coeficiente: 0.9039\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = data[\"clase\"]  # Variable objetivo (la columna 'classe')\n",
    "#usamos dos corchetes para indicar que X es un Dataframe y no un vector\n",
    "#  unidimensional Serie,ya que sino da error en el metodo fit\n",
    "X = data[[\"V7\",\"V1\"]]  # Característica V7 soolo\n",
    "print(y)\n",
    "print(X)\n",
    "\n",
    "n=100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "mse_results =[]\n",
    "mae_results =[]\n",
    "mse_train = []\n",
    "mae_train = []\n",
    "r2_results =[]\n",
    "r2_train = []\n",
    "error_test =[]\n",
    "error_train = []\n",
    "for i in range(n):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=i)\n",
    "\n",
    "\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Train Predict\n",
    "\n",
    "    y_predict = model.predict(X_train)\n",
    "    mse_train.append(mean_squared_error(y_train,  y_predict))\n",
    "    mae_train.append(mean_absolute_error(y_train, y_predict))\n",
    "    r2_train.append(r2_score(y_train , y_predict))\n",
    "    error_train.append(y_train  - (y_predict))\n",
    "    print(i)\n",
    "    # Test Predict\n",
    "    y_predict = model.predict(X_test)\n",
    "    mse_results.append(mean_squared_error(y_test,  y_predict))\n",
    "    mae_results.append(mean_absolute_error(y_test, y_predict))\n",
    "    r2_results.append(r2_score(y_test , y_predict))\n",
    "    error_test.append(y_test  - (y_predict))\n",
    "    #mostramos amtriz de confusionpara cada modelo\n",
    "    conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(conf_matrix)\n",
    "    #mostramos reporte de calsificacion\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Figure\n",
    "\n",
    "\n",
    "# Predict on training data\n",
    "print(f\"Mean squared error (Train): {np.mean(mse_train)} \")\n",
    "print(f\"Absolute squared error (Train): {np.mean(mae_train)} \")\n",
    "print(f\"R2 score (Train): {np.mean(r2_train)} \")\n",
    "\n",
    "# Predict on test data\n",
    "print(f\"Mean squared error (Test): {np.mean(mse_results)} \")\n",
    "print(f\"Absolute squared error (Test): {np.mean(mae_results)} \")\n",
    "print(f\"R2 score (Test): {np.mean(r2_results)} \")\n",
    "\n",
    "# Obtener los coeficientes del modelo\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Mostrar los coeficientes junto con los nombres de las características\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Característica: {feature}, Coeficiente: {coef:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo ha mejorado respecto al anterior pero sigue siendo ligeramente inferior al primer modelo que usaba todas las características.\n",
    "\n",
    "Siguen ampliando el número de características justificando el orden de inclusión. ¿Cómo mejoran los resultados al ir añadiendo nuevas características?\n",
    "\n",
    "Las siguientes 3 características que voy a añadir a la lista de características van a ser V6 ,V4 Y V9 ya eran las 3 características que empataban(prácticamente) en el tercer puesto de características con más influencia en la predición del modelo con todas las características.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "694    0\n",
      "695    0\n",
      "696    1\n",
      "697    1\n",
      "698    1\n",
      "Name: clase, Length: 683, dtype: int64\n",
      "     V7  V1    V6  V4  V9\n",
      "0     3   5   1.0   1   1\n",
      "1     3   5  10.0   5   1\n",
      "2     3   3   2.0   1   1\n",
      "3     3   6   4.0   1   1\n",
      "4     3   4   1.0   3   1\n",
      "..   ..  ..   ...  ..  ..\n",
      "694   1   3   2.0   1   1\n",
      "695   1   2   1.0   1   1\n",
      "696   8   5   3.0   3   2\n",
      "697  10   4   4.0   4   1\n",
      "698  10   4   5.0   5   1\n",
      "\n",
      "[683 rows x 5 columns]\n",
      "0\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 3 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        87\n",
      "           1       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "1\n",
      "Matriz de confusión:\n",
      "[[90  0]\n",
      " [ 2 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        90\n",
      "           1       1.00      0.96      0.98        47\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "2\n",
      "Matriz de confusión:\n",
      "[[80  3]\n",
      " [ 3 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        83\n",
      "           1       0.94      0.94      0.94        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "3\n",
      "Matriz de confusión:\n",
      "[[75  3]\n",
      " [ 4 55]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96        78\n",
      "           1       0.95      0.93      0.94        59\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "4\n",
      "Matriz de confusión:\n",
      "[[86  4]\n",
      " [ 0 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        90\n",
      "           1       0.92      1.00      0.96        47\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.96      0.98      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "5\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 2 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        90\n",
      "           1       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "6\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 2 54]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        81\n",
      "           1       0.98      0.96      0.97        56\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "7\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        89\n",
      "           1       0.94      0.96      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "8\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 3 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        84\n",
      "           1       1.00      0.94      0.97        53\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "9\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        84\n",
      "           1       1.00      0.96      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "10\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        89\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "11\n",
      "Matriz de confusión:\n",
      "[[84  2]\n",
      " [ 2 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        86\n",
      "           1       0.96      0.96      0.96        51\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "12\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 3 53]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        81\n",
      "           1       0.98      0.95      0.96        56\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "13\n",
      "Matriz de confusión:\n",
      "[[88  3]\n",
      " [ 6 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        91\n",
      "           1       0.93      0.87      0.90        46\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.93      0.92      0.93       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "14\n",
      "Matriz de confusión:\n",
      "[[83  1]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        84\n",
      "           1       0.98      0.96      0.97        53\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "15\n",
      "Matriz de confusión:\n",
      "[[78  3]\n",
      " [ 5 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        81\n",
      "           1       0.94      0.91      0.93        56\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "16\n",
      "Matriz de confusión:\n",
      "[[90  2]\n",
      " [ 3 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        92\n",
      "           1       0.95      0.93      0.94        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "17\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        88\n",
      "           1       0.94      0.96      0.95        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "18\n",
      "Matriz de confusión:\n",
      "[[79  2]\n",
      " [ 3 53]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        81\n",
      "           1       0.96      0.95      0.95        56\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "19\n",
      "Matriz de confusión:\n",
      "[[92  1]\n",
      " [ 5 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        93\n",
      "           1       0.97      0.89      0.93        44\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "20\n",
      "Matriz de confusión:\n",
      "[[95  4]\n",
      " [ 2 36]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        99\n",
      "           1       0.90      0.95      0.92        38\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.94      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "21\n",
      "Matriz de confusión:\n",
      "[[84  0]\n",
      " [ 4 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        84\n",
      "           1       1.00      0.92      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "22\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        89\n",
      "           1       0.98      0.96      0.97        48\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "23\n",
      "Matriz de confusión:\n",
      "[[82  1]\n",
      " [ 3 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        83\n",
      "           1       0.98      0.94      0.96        54\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "24\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 4 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        88\n",
      "           1       0.94      0.92      0.93        49\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "25\n",
      "Matriz de confusión:\n",
      "[[93  3]\n",
      " [ 1 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        96\n",
      "           1       0.93      0.98      0.95        41\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.96      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "26\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 0 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        89\n",
      "           1       0.96      1.00      0.98        48\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.99      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "27\n",
      "Matriz de confusión:\n",
      "[[82  2]\n",
      " [ 2 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        84\n",
      "           1       0.96      0.96      0.96        53\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "28\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [ 9 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        88\n",
      "           1       0.98      0.82      0.89        49\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.90      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "29\n",
      "Matriz de confusión:\n",
      "[[92  1]\n",
      " [ 4 40]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        93\n",
      "           1       0.98      0.91      0.94        44\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "30\n",
      "Matriz de confusión:\n",
      "[[92  4]\n",
      " [ 4 37]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        96\n",
      "           1       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.93      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "31\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 3 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        91\n",
      "           1       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "32\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 7 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96        87\n",
      "           1       0.98      0.86      0.91        50\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.92      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "33\n",
      "Matriz de confusión:\n",
      "[[80  1]\n",
      " [ 2 54]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        81\n",
      "           1       0.98      0.96      0.97        56\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "34\n",
      "Matriz de confusión:\n",
      "[[84  3]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        87\n",
      "           1       0.94      0.92      0.93        50\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "35\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        88\n",
      "           1       0.92      0.96      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "36\n",
      "Matriz de confusión:\n",
      "[[81  2]\n",
      " [ 5 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        83\n",
      "           1       0.96      0.91      0.93        54\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "37\n",
      "Matriz de confusión:\n",
      "[[80  2]\n",
      " [ 3 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        82\n",
      "           1       0.96      0.95      0.95        55\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "38\n",
      "Matriz de confusión:\n",
      "[[84  2]\n",
      " [ 3 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        86\n",
      "           1       0.96      0.94      0.95        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "39\n",
      "Matriz de confusión:\n",
      "[[89  0]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        89\n",
      "           1       1.00      0.92      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "40\n",
      "Matriz de confusión:\n",
      "[[87  0]\n",
      " [ 4 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        87\n",
      "           1       1.00      0.92      0.96        50\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "41\n",
      "Matriz de confusión:\n",
      "[[91  5]\n",
      " [ 2 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        96\n",
      "           1       0.89      0.95      0.92        41\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.93      0.95      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "42\n",
      "Matriz de confusión:\n",
      "[[78  1]\n",
      " [ 5 53]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        79\n",
      "           1       0.98      0.91      0.95        58\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "43\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [ 5 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        88\n",
      "           1       0.98      0.90      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "44\n",
      "Matriz de confusión:\n",
      "[[82  4]\n",
      " [ 3 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96        86\n",
      "           1       0.92      0.94      0.93        51\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.95      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "45\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 3 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        91\n",
      "           1       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "46\n",
      "Matriz de confusión:\n",
      "[[83  1]\n",
      " [ 1 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        84\n",
      "           1       0.98      0.98      0.98        53\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "47\n",
      "Matriz de confusión:\n",
      "[[87  1]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        88\n",
      "           1       0.98      0.96      0.97        49\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "48\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [ 1 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97        89\n",
      "           1       0.90      0.98      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "49\n",
      "Matriz de confusión:\n",
      "[[80  3]\n",
      " [ 3 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        83\n",
      "           1       0.94      0.94      0.94        54\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "50\n",
      "Matriz de confusión:\n",
      "[[85  0]\n",
      " [ 2 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        85\n",
      "           1       1.00      0.96      0.98        52\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "51\n",
      "Matriz de confusión:\n",
      "[[83  0]\n",
      " [ 2 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        83\n",
      "           1       1.00      0.96      0.98        54\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "52\n",
      "Matriz de confusión:\n",
      "[[88  2]\n",
      " [ 1 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        90\n",
      "           1       0.96      0.98      0.97        47\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "53\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 6 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        89\n",
      "           1       0.95      0.88      0.91        48\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.95      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "54\n",
      "Matriz de confusión:\n",
      "[[86  3]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        89\n",
      "           1       0.94      0.94      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "55\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 4 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        89\n",
      "           1       0.96      0.92      0.94        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "56\n",
      "Matriz de confusión:\n",
      "[[87  2]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        89\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "57\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 3 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        92\n",
      "           1       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "58\n",
      "Matriz de confusión:\n",
      "[[85  3]\n",
      " [ 5 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        88\n",
      "           1       0.94      0.90      0.92        49\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.93      0.94       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "59\n",
      "Matriz de confusión:\n",
      "[[88  2]\n",
      " [ 5 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        90\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "60\n",
      "Matriz de confusión:\n",
      "[[85  2]\n",
      " [ 3 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        87\n",
      "           1       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "61\n",
      "Matriz de confusión:\n",
      "[[76  4]\n",
      " [ 7 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93        80\n",
      "           1       0.93      0.88      0.90        57\n",
      "\n",
      "    accuracy                           0.92       137\n",
      "   macro avg       0.92      0.91      0.92       137\n",
      "weighted avg       0.92      0.92      0.92       137\n",
      "\n",
      "62\n",
      "Matriz de confusión:\n",
      "[[87  0]\n",
      " [ 2 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        87\n",
      "           1       1.00      0.96      0.98        50\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "63\n",
      "Matriz de confusión:\n",
      "[[96  1]\n",
      " [ 6 34]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        97\n",
      "           1       0.97      0.85      0.91        40\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.92      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "64\n",
      "Matriz de confusión:\n",
      "[[84  5]\n",
      " [ 0 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        89\n",
      "           1       0.91      1.00      0.95        48\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.97      0.96       137\n",
      "weighted avg       0.97      0.96      0.96       137\n",
      "\n",
      "65\n",
      "Matriz de confusión:\n",
      "[[81  3]\n",
      " [ 3 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        84\n",
      "           1       0.94      0.94      0.94        53\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "66\n",
      "Matriz de confusión:\n",
      "[[94  2]\n",
      " [ 0 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        96\n",
      "           1       0.95      1.00      0.98        41\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.99      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "67\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        89\n",
      "           1       0.98      0.96      0.97        48\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "68\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 6 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        87\n",
      "           1       0.98      0.88      0.93        50\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "69\n",
      "Matriz de confusión:\n",
      "[[89  3]\n",
      " [ 3 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        92\n",
      "           1       0.93      0.93      0.93        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "70\n",
      "Matriz de confusión:\n",
      "[[84  1]\n",
      " [ 4 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        85\n",
      "           1       0.98      0.92      0.95        52\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "71\n",
      "Matriz de confusión:\n",
      "[[82  1]\n",
      " [ 2 52]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        83\n",
      "           1       0.98      0.96      0.97        54\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "72\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        88\n",
      "           1       0.96      0.96      0.96        49\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "73\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 2 46]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        89\n",
      "           1       0.98      0.96      0.97        48\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "74\n",
      "Matriz de confusión:\n",
      "[[88  1]\n",
      " [ 3 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        89\n",
      "           1       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "75\n",
      "Matriz de confusión:\n",
      "[[84  3]\n",
      " [ 3 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        87\n",
      "           1       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "76\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 4 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        92\n",
      "           1       0.98      0.91      0.94        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "77\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 1 45]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        91\n",
      "           1       0.96      0.98      0.97        46\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "78\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 1 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        87\n",
      "           1       0.98      0.98      0.98        50\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.98      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "79\n",
      "Matriz de confusión:\n",
      "[[86  1]\n",
      " [ 6 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        87\n",
      "           1       0.98      0.88      0.93        50\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.96      0.93      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "80\n",
      "Matriz de confusión:\n",
      "[[91  1]\n",
      " [ 3 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        92\n",
      "           1       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "81\n",
      "Matriz de confusión:\n",
      "[[95  0]\n",
      " [ 3 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        95\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.96      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "82\n",
      "Matriz de confusión:\n",
      "[[74  3]\n",
      " [ 2 58]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97        77\n",
      "           1       0.95      0.97      0.96        60\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "83\n",
      "Matriz de confusión:\n",
      "[[89  3]\n",
      " [ 2 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        92\n",
      "           1       0.93      0.96      0.95        45\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "84\n",
      "Matriz de confusión:\n",
      "[[92  1]\n",
      " [ 2 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        93\n",
      "           1       0.98      0.95      0.97        44\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.98      0.97      0.97       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "85\n",
      "Matriz de confusión:\n",
      "[[88  3]\n",
      " [ 3 43]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        91\n",
      "           1       0.93      0.93      0.93        46\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "86\n",
      "Matriz de confusión:\n",
      "[[87  3]\n",
      " [ 3 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        90\n",
      "           1       0.94      0.94      0.94        47\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "87\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        88\n",
      "           1       0.96      0.96      0.96        49\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "88\n",
      "Matriz de confusión:\n",
      "[[93  1]\n",
      " [ 4 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        94\n",
      "           1       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.97      0.95      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "89\n",
      "Matriz de confusión:\n",
      "[[88  4]\n",
      " [ 4 41]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        92\n",
      "           1       0.91      0.91      0.91        45\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.93      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "90\n",
      "Matriz de confusión:\n",
      "[[86  2]\n",
      " [ 0 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        88\n",
      "           1       0.96      1.00      0.98        49\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.98      0.99      0.98       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "91\n",
      "Matriz de confusión:\n",
      "[[89  1]\n",
      " [ 5 42]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        90\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.94      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "92\n",
      "Matriz de confusión:\n",
      "[[94  1]\n",
      " [ 3 39]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        95\n",
      "           1       0.97      0.93      0.95        42\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.96      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "93\n",
      "Matriz de confusión:\n",
      "[[89  2]\n",
      " [ 2 44]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        91\n",
      "           1       0.96      0.96      0.96        46\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "94\n",
      "Matriz de confusión:\n",
      "[[88  0]\n",
      " [ 1 48]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        88\n",
      "           1       1.00      0.98      0.99        49\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "95\n",
      "Matriz de confusión:\n",
      "[[84  2]\n",
      " [ 1 50]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        86\n",
      "           1       0.96      0.98      0.97        51\n",
      "\n",
      "    accuracy                           0.98       137\n",
      "   macro avg       0.97      0.98      0.98       137\n",
      "weighted avg       0.98      0.98      0.98       137\n",
      "\n",
      "96\n",
      "Matriz de confusión:\n",
      "[[85  0]\n",
      " [ 1 51]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        85\n",
      "           1       1.00      0.98      0.99        52\n",
      "\n",
      "    accuracy                           0.99       137\n",
      "   macro avg       0.99      0.99      0.99       137\n",
      "weighted avg       0.99      0.99      0.99       137\n",
      "\n",
      "97\n",
      "Matriz de confusión:\n",
      "[[84  4]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        88\n",
      "           1       0.92      0.96      0.94        49\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "98\n",
      "Matriz de confusión:\n",
      "[[81  3]\n",
      " [ 4 49]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96        84\n",
      "           1       0.94      0.92      0.93        53\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "99\n",
      "Matriz de confusión:\n",
      "[[91  3]\n",
      " [ 5 38]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        94\n",
      "           1       0.93      0.88      0.90        43\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.94      0.93      0.93       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "Mean squared error (Train): 0.032582417582417575 \n",
      "Absolute squared error (Train): 0.032582417582417575 \n",
      "R2 score (Train): 0.8563135606277517 \n",
      "Mean squared error (Test): 0.035693430656934304 \n",
      "Absolute squared error (Test): 0.035693430656934304 \n",
      "R2 score (Test): 0.8435421762027072 \n",
      "Característica: V7, Coeficiente: 0.9519\n",
      "Característica: V1, Coeficiente: 0.6673\n",
      "Característica: V6, Coeficiente: 0.4234\n",
      "Característica: V4, Coeficiente: 0.4169\n",
      "Característica: V9, Coeficiente: 0.3937\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = data[\"clase\"]  # Variable objetivo (la columna 'classe')\n",
    "#usamos dos corchetes para indicar que X es un Dataframe y no un vector\n",
    "#  unidimensional Serie,ya que sino da error en el metodo fit\n",
    "X = data[[\"V7\",\"V1\",\"V6\",\"V4\",\"V9\"]]  # Característica V7 soolo\n",
    "print(y)\n",
    "print(X)\n",
    "\n",
    "n=100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "mse_results =[]\n",
    "mae_results =[]\n",
    "mse_train = []\n",
    "mae_train = []\n",
    "r2_results =[]\n",
    "r2_train = []\n",
    "error_test =[]\n",
    "error_train = []\n",
    "for i in range(n):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=i)\n",
    "\n",
    "\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Train Predict\n",
    "\n",
    "    y_predict = model.predict(X_train)\n",
    "    mse_train.append(mean_squared_error(y_train,  y_predict))\n",
    "    mae_train.append(mean_absolute_error(y_train, y_predict))\n",
    "    r2_train.append(r2_score(y_train , y_predict))\n",
    "    error_train.append(y_train  - (y_predict))\n",
    "    print(i)\n",
    "    # Test Predict\n",
    "    y_predict = model.predict(X_test)\n",
    "    mse_results.append(mean_squared_error(y_test,  y_predict))\n",
    "    mae_results.append(mean_absolute_error(y_test, y_predict))\n",
    "    r2_results.append(r2_score(y_test , y_predict))\n",
    "    error_test.append(y_test  - (y_predict))\n",
    "    #mostramos amtriz de confusionpara cada modelo\n",
    "    conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(conf_matrix)\n",
    "    #mostramos reporte de calsificacion\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "\n",
    "# Figure\n",
    "\n",
    "\n",
    "# Predict on training data\n",
    "print(f\"Mean squared error (Train): {np.mean(mse_train)} \")\n",
    "print(f\"Absolute squared error (Train): {np.mean(mae_train)} \")\n",
    "print(f\"R2 score (Train): {np.mean(r2_train)} \")\n",
    "\n",
    "# Predict on test data\n",
    "print(f\"Mean squared error (Test): {np.mean(mse_results)} \")\n",
    "print(f\"Absolute squared error (Test): {np.mean(mae_results)} \")\n",
    "print(f\"R2 score (Test): {np.mean(r2_results)} \")\n",
    "\n",
    "# Obtener los coeficientes del modelo\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Mostrar los coeficientes junto con los nombres de las características\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    print(f\"Característica: {feature}, Coeficiente: {coef:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando las características V7,V1,V6,V4 Y V9 obtenemos un r2score de 0.843,es decir un mejor rendimiento que el modelo que utilizaba todas las características"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
